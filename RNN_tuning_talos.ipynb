{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754b8cd1",
   "metadata": {},
   "source": [
    "## Based on https://www.tensorflow.org/tutorials/load_data/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1f75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d719926",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"OSA_complete_patients.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97a3e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Current_smoker</th>\n",
       "      <th>Former_smoker</th>\n",
       "      <th>Sedentary</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Cervical_perimeter</th>\n",
       "      <th>Abdominal_perimeter</th>\n",
       "      <th>...</th>\n",
       "      <th>Nocturnal_perspiration</th>\n",
       "      <th>Shortness_of_breath_on_exertion</th>\n",
       "      <th>Nocturia</th>\n",
       "      <th>Drowsiness_accident</th>\n",
       "      <th>Near_miss_accident</th>\n",
       "      <th>Respiratory_arrest</th>\n",
       "      <th>Epworth_scale</th>\n",
       "      <th>Pichots_scale</th>\n",
       "      <th>Depression_scale</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.883641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.796715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.438741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.736482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.802190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PatientID  Sex        Age  Current_smoker  Former_smoker  Sedentary  \\\n",
       "39         23  2.0  57.883641             0.0            0.0        0.0   \n",
       "41         24  2.0  60.796715             0.0            0.0        0.0   \n",
       "46         28  1.0  63.438741             0.0            0.0        0.0   \n",
       "55         32  1.0  28.736482             0.0            0.0        0.0   \n",
       "56         33  1.0  56.802190             0.0            0.0        0.0   \n",
       "\n",
       "    Height  Weight  Cervical_perimeter  Abdominal_perimeter  ...  \\\n",
       "39   172.0    90.0                45.0                125.0  ...   \n",
       "41   156.0    85.0                35.0                113.0  ...   \n",
       "46   178.0    68.0                35.0                 73.0  ...   \n",
       "55   180.0    69.0                36.0                 83.0  ...   \n",
       "56   185.0   118.0                43.0                106.0  ...   \n",
       "\n",
       "    Nocturnal_perspiration  Shortness_of_breath_on_exertion  Nocturia  \\\n",
       "39                     0.0                              0.0       1.0   \n",
       "41                     0.0                              1.0       1.0   \n",
       "46                     0.0                              0.0       1.0   \n",
       "55                     0.0                              0.0       0.0   \n",
       "56                     0.0                              0.0       0.0   \n",
       "\n",
       "    Drowsiness_accident  Near_miss_accident  Respiratory_arrest  \\\n",
       "39                  0.0                 0.0                 0.0   \n",
       "41                  0.0                 0.0                 1.0   \n",
       "46                  0.0                 0.0                 1.0   \n",
       "55                  0.0                 0.0                 0.0   \n",
       "56                  0.0                 0.0                 1.0   \n",
       "\n",
       "    Epworth_scale  Pichots_scale  Depression_scale  Severity  \n",
       "39            3.0            4.0               5.0         3  \n",
       "41           19.0           17.0               4.0         3  \n",
       "46            5.0            3.0               0.0         1  \n",
       "55            2.0            0.0               0.0         0  \n",
       "56           12.0           13.0               2.0         3  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad7bc0",
   "metadata": {},
   "source": [
    "### One hot encoding the class labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef93a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Current_smoker</th>\n",
       "      <th>Former_smoker</th>\n",
       "      <th>Sedentary</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Cervical_perimeter</th>\n",
       "      <th>Abdominal_perimeter</th>\n",
       "      <th>...</th>\n",
       "      <th>Near_miss_accident</th>\n",
       "      <th>Respiratory_arrest</th>\n",
       "      <th>Epworth_scale</th>\n",
       "      <th>Pichots_scale</th>\n",
       "      <th>Depression_scale</th>\n",
       "      <th>Severity</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.883641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.796715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.438741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.736482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.802190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190460</th>\n",
       "      <td>111385</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.596167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190467</th>\n",
       "      <td>111392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.539357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190469</th>\n",
       "      <td>111394</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.986995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190502</th>\n",
       "      <td>111424</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.698836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190525</th>\n",
       "      <td>111444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.370979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21818 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PatientID  Sex        Age  Current_smoker  Former_smoker  Sedentary  \\\n",
       "39             23  2.0  57.883641             0.0            0.0        0.0   \n",
       "41             24  2.0  60.796715             0.0            0.0        0.0   \n",
       "46             28  1.0  63.438741             0.0            0.0        0.0   \n",
       "55             32  1.0  28.736482             0.0            0.0        0.0   \n",
       "56             33  1.0  56.802190             0.0            0.0        0.0   \n",
       "...           ...  ...        ...             ...            ...        ...   \n",
       "190460     111385  2.0  53.596167             0.0            0.0        1.0   \n",
       "190467     111392  1.0  72.539357             0.0            1.0        1.0   \n",
       "190469     111394  2.0  46.986995             0.0            1.0        1.0   \n",
       "190502     111424  2.0  75.698836             0.0            1.0        0.0   \n",
       "190525     111444  2.0  70.370979             0.0            0.0        1.0   \n",
       "\n",
       "        Height  Weight  Cervical_perimeter  Abdominal_perimeter  ...  \\\n",
       "39       172.0    90.0                45.0                125.0  ...   \n",
       "41       156.0    85.0                35.0                113.0  ...   \n",
       "46       178.0    68.0                35.0                 73.0  ...   \n",
       "55       180.0    69.0                36.0                 83.0  ...   \n",
       "56       185.0   118.0                43.0                106.0  ...   \n",
       "...        ...     ...                 ...                  ...  ...   \n",
       "190460   164.0    88.0                37.0                 92.0  ...   \n",
       "190467   167.0    67.0                39.0                 89.0  ...   \n",
       "190469   158.0    56.0                35.0                 89.0  ...   \n",
       "190502   150.0    68.0                36.0                 96.0  ...   \n",
       "190525   155.0    67.0                35.0                100.0  ...   \n",
       "\n",
       "        Near_miss_accident  Respiratory_arrest  Epworth_scale  Pichots_scale  \\\n",
       "39                     0.0                 0.0            3.0            4.0   \n",
       "41                     0.0                 1.0           19.0           17.0   \n",
       "46                     0.0                 1.0            5.0            3.0   \n",
       "55                     0.0                 0.0            2.0            0.0   \n",
       "56                     0.0                 1.0           12.0           13.0   \n",
       "...                    ...                 ...            ...            ...   \n",
       "190460                 0.0                 0.0            2.0           14.0   \n",
       "190467                 0.0                 1.0            4.0            1.0   \n",
       "190469                 1.0                 0.0           15.0           24.0   \n",
       "190502                 0.0                 0.0            5.0           16.0   \n",
       "190525                 0.0                 0.0            2.0            7.0   \n",
       "\n",
       "        Depression_scale  Severity    0    1    2    3  \n",
       "39                   5.0         3  0.0  0.0  0.0  1.0  \n",
       "41                   4.0         3  0.0  0.0  0.0  1.0  \n",
       "46                   0.0         1  0.0  1.0  0.0  0.0  \n",
       "55                   0.0         0  1.0  0.0  0.0  0.0  \n",
       "56                   2.0         3  0.0  0.0  0.0  1.0  \n",
       "...                  ...       ...  ...  ...  ...  ...  \n",
       "190460               4.0         1  0.0  1.0  0.0  0.0  \n",
       "190467               0.0         3  0.0  0.0  0.0  1.0  \n",
       "190469               6.0         1  0.0  1.0  0.0  0.0  \n",
       "190502               8.0         3  0.0  0.0  0.0  1.0  \n",
       "190525               3.0         3  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[21818 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# passing severoty column (label encoded values of severities)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(data[['Severity']]).toarray(), index = data.index)\n",
    "\n",
    "\n",
    "# merge with main df bridge_df on key values\n",
    "data2 = pd.concat([data, enc_df], axis = 1)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129f2320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21818, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1202e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Sex', 'Age', 'Current_smoker', 'Former_smoker',\n",
    "       'Sedentary', 'Height', 'Weight', 'Cervical_perimeter',\n",
    "       'Abdominal_perimeter', 'Systolic_BP', 'Diastolic_BP',\n",
    "       'Maxillofacial_profile', 'BMI', 'High_BP', 'Asthma', 'Rhinitis', 'COPD',\n",
    "       'Respiratory_fail', 'Myocardial_infarct', 'Coronary_fail',\n",
    "       'Arrhythmias', 'Stroke', 'Heart_fail', 'Arteriopathy', 'Gastric_reflux',\n",
    "       'Glaucoma', 'Diabetes', 'Hypercholesterolemia', 'Hypertriglyceridemia',\n",
    "       'Hypo(er)thyroidism', 'Depression', 'Obesity', 'Dysmorphology',\n",
    "       'Restless_Leg_Syndrome', 'Snoring', 'Diurnal_somnolence',\n",
    "       'Driving_drowsiness', 'Morning_fatigue', 'Morning_headache',\n",
    "       'Memory_problem', 'Nocturnal_perspiration',\n",
    "       'Shortness_of_breath_on_exertion', 'Nocturia', 'Drowsiness_accident',\n",
    "       'Near_miss_accident', 'Respiratory_arrest', 'Epworth_scale',\n",
    "       'Pichots_scale', 'Depression_scale']\n",
    "\n",
    "continuous = ['Age','Height','Weight','Cervical_perimeter','Abdominal_perimeter','Systolic_BP','Diastolic_BP',\n",
    "              'BMI','Epworth_scale','Pichots_scale','Depression_scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87886b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[features]  # Features  \n",
    "y=data['Severity']  # Labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2143473",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()  \n",
    "    # Scale only on training data\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "    # apply same transformation to test data\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5aa428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17454, 49) (4364, 49)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d94caa",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c28082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, activation = 'relu', return_sequences = True))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.LSTM(128, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu')) \n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(4, activation = 'softmax')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e06f152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17454, 49)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12626f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = X_train.reshape(X_train.shape[0],1,49) # LSTM requires a 3D array in the format: (# samples, timesteps, # features)\n",
    "\n",
    "X_test_lstm = X_test.reshape(X_test.shape[0], 1, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c42c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17454, 1, 49)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c0a31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amona\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 24s 21ms/step - loss: 1.3794 - accuracy: 0.3898\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 11s 21ms/step - loss: 1.3606 - accuracy: 0.4023\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 13s 24ms/step - loss: 1.3306 - accuracy: 0.4023\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 12s 22ms/step - loss: 1.3038 - accuracy: 0.4023\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 1.2936 - accuracy: 0.4023\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 1.2867 - accuracy: 0.4023\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 14s 26ms/step - loss: 1.2828 - accuracy: 0.4023\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 14s 25ms/step - loss: 1.2759 - accuracy: 0.4023\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 13s 24ms/step - loss: 1.2709 - accuracy: 0.4023\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 14s 25ms/step - loss: 1.2658 - accuracy: 0.4023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28aad55a820>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr = 1e-5, decay = 1e-5)  # the optimizer settings can have a large impact. Decay, decreases the learning rate\n",
    "model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train_lstm, y_train, epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b373efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 3s 10ms/step - loss: 1.2615 - accuracy: 0.4024\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test_lstm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c07ba63",
   "metadata": {},
   "source": [
    "### SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7574b928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 8s 8ms/step - loss: 1.3711 - accuracy: 0.2594\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 5s 8ms/step - loss: 1.3563 - accuracy: 0.2947\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 5s 9ms/step - loss: 1.3454 - accuracy: 0.3223\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 5s 8ms/step - loss: 1.3371 - accuracy: 0.3525\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 4s 8ms/step - loss: 1.3305 - accuracy: 0.3709\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 5s 8ms/step - loss: 1.3253 - accuracy: 0.3833\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 5s 9ms/step - loss: 1.3209 - accuracy: 0.3906\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 6s 11ms/step - loss: 1.3172 - accuracy: 0.3956\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 7s 13ms/step - loss: 1.3139 - accuracy: 0.3986\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 5s 10ms/step - loss: 1.3110 - accuracy: 0.4001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28ab4be0a60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.SimpleRNN(12, activation = 'tanh'))\n",
    "model.add(tf.keras.layers.Dense(12, activation = 'relu')) \n",
    "model.add(tf.keras.layers.Dense(4, activation = 'softmax')) \n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr = 1e-5, decay = 1e-5)  # the optimizer settings can have a large impact. Decay, decreases the learning rate\n",
    "model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train_lstm, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69ad15df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 3s 7ms/step - loss: 1.3096 - accuracy: 0.4008\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test_lstm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb1511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f87515d",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization simple RNN\n",
    "from https://towardsdatascience.com/hyperparameter-optimization-with-keras-b82e6364ca53\n",
    "\n",
    "https://nbviewer.org/github/autonomio/talos/blob/master/examples/Hyperparameter%20Optimization%20with%20Keras%20for%20the%20Iris%20Prediction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86114d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "%matplotlib inline\n",
    "\n",
    "from talos.utils import lr_normalizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, SimpleRNN, LSTM\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.losses import categorical_crossentropy, logcosh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2326a1",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8daab160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.4246951 , 0.        , ..., 0.125     , 0.125     ,\n",
       "        0.38461538],\n",
       "       [1.        , 0.45573904, 0.        , ..., 0.79166667, 0.53125   ,\n",
       "        0.30769231],\n",
       "       [0.        , 0.4838945 , 0.        , ..., 0.20833333, 0.09375   ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.3085721 , 0.        , ..., 0.625     , 0.75      ,\n",
       "        0.46153846],\n",
       "       [1.        , 0.61454747, 0.        , ..., 0.20833333, 0.5       ,\n",
       "        0.61538462],\n",
       "       [1.        , 0.55776974, 0.        , ..., 0.08333333, 0.21875   ,\n",
       "        0.23076923]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = MinMaxScaler(feature_range = (0, 1))  \n",
    "    # Scale only on training data\n",
    "mm.fit(data[features])  \n",
    "x = mm.transform(data[features])  \n",
    " \n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2f4292a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = enc_df.to_numpy()\n",
    "y\n",
    "\n",
    "# the talos example used arrays for x and y, and y was one-hot encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dc110623",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0],1,49) # LSTM requires a 3D array in the format: (# samples, timesteps, # features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d28139",
   "metadata": {},
   "source": [
    "### Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b08f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSA_model(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    model = Sequential()                            \n",
    "    model.add(SimpleRNN(params['first_neuron'],\n",
    "                    activation=params['first_activation']))\n",
    "    \n",
    "    model.add(Dense(params['first_neuron'],\n",
    "                    input_dim=x_train.shape[1],\n",
    "                    activation=params['second_activation']))\n",
    "    \n",
    "    model.add(Dense(y_train.shape[1],\n",
    "                    activation=params['last_activation']))\n",
    "\n",
    "    model.compile(optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])),\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=1,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80765a",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d56136ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'lr': (0.001, 0.01, 0.1),\n",
    "     'first_neuron':[4, 8, 16, 32, 64, 128],\n",
    "     'batch_size': [5, 10, 20],\n",
    "     'epochs': [5],\n",
    "     'optimizer': [Adam, Nadam, Adamax],\n",
    "     'loss': ['categorical_crossentropy'],\n",
    "     'first_activation': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "     'second_activation': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "     'last_activation': ['softmax']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4e5c4",
   "metadata": {},
   "source": [
    "### Run the Hyperparameter Scan() \n",
    "\n",
    "the documentation for this function is here:\n",
    "https://github.com/autonomio/talos/blob/master/talos/scan/Scan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc13256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/230 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 62s 13ms/step - loss: 1.2710 - acc: 0.4182 - val_loss: 1.2284 - val_acc: 0.4433\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 38s 10ms/step - loss: 1.2132 - acc: 0.4556 - val_loss: 1.2170 - val_acc: 0.4452\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 38s 10ms/step - loss: 1.1977 - acc: 0.4619 - val_loss: 1.2071 - val_acc: 0.4502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/230 [02:18<8:49:54, 138.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 34s 8ms/step - loss: 1.2199 - acc: 0.4500 - val_loss: 1.1953 - val_acc: 0.4572\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 38s 10ms/step - loss: 1.1944 - acc: 0.4610 - val_loss: 1.2113 - val_acc: 0.4456\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 39s 10ms/step - loss: 1.1882 - acc: 0.4616 - val_loss: 1.2053 - val_acc: 0.4441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 2/230 [04:10<7:46:27, 122.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 34s 8ms/step - loss: 1.2839 - acc: 0.4069 - val_loss: 1.2491 - val_acc: 0.4172\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 40s 10ms/step - loss: 1.2214 - acc: 0.4442 - val_loss: 1.2166 - val_acc: 0.4482\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 36s 10ms/step - loss: 1.2022 - acc: 0.4559 - val_loss: 1.2029 - val_acc: 0.4537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 3/230 [06:01<7:25:07, 117.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 33s 8ms/step - loss: 1.2573 - acc: 0.4359 - val_loss: 1.2320 - val_acc: 0.4450\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 37s 10ms/step - loss: 1.2147 - acc: 0.4589 - val_loss: 1.2132 - val_acc: 0.4504\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 36s 9ms/step - loss: 1.1994 - acc: 0.4619 - val_loss: 1.2044 - val_acc: 0.4519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 4/230 [07:48<7:06:48, 113.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 44s 10ms/step - loss: 1.2391 - acc: 0.4410 - val_loss: 1.2114 - val_acc: 0.4459\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 36s 9ms/step - loss: 1.1951 - acc: 0.4601 - val_loss: 1.1940 - val_acc: 0.4562\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 36s 9ms/step - loss: 1.1811 - acc: 0.4655 - val_loss: 1.1906 - val_acc: 0.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 5/230 [09:44<7:08:58, 114.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 42s 10ms/step - loss: 1.2272 - acc: 0.4441 - val_loss: 1.1963 - val_acc: 0.4529\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 36s 9ms/step - loss: 1.1913 - acc: 0.4597 - val_loss: 1.1898 - val_acc: 0.4575\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 38s 10ms/step - loss: 1.1829 - acc: 0.4642 - val_loss: 1.1876 - val_acc: 0.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 6/230 [11:42<7:11:15, 115.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 39s 10ms/step - loss: 1.2269 - acc: 0.4448 - val_loss: 1.2166 - val_acc: 0.4445\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 35s 9ms/step - loss: 1.1902 - acc: 0.4614 - val_loss: 1.1891 - val_acc: 0.4633\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 35s 9ms/step - loss: 1.1846 - acc: 0.4646 - val_loss: 1.1848 - val_acc: 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 7/230 [13:32<7:02:10, 113.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 82s 10ms/step - loss: 1.2256 - acc: 0.4432 - val_loss: 1.2047 - val_acc: 0.4568\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 83s 11ms/step - loss: 1.1989 - acc: 0.4612 - val_loss: 1.2042 - val_acc: 0.4548\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 82s 11ms/step - loss: 1.1932 - acc: 0.4626 - val_loss: 1.1970 - val_acc: 0.4623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 8/230 [17:40<9:39:11, 156.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 45s 10ms/step - loss: 1.2242 - acc: 0.4379 - val_loss: 1.1861 - val_acc: 0.4626\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 45s 12ms/step - loss: 1.1918 - acc: 0.4608 - val_loss: 1.1790 - val_acc: 0.4656\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 42s 11ms/step - loss: 1.1803 - acc: 0.4617 - val_loss: 1.1934 - val_acc: 0.4597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 9/230 [19:54<9:10:00, 149.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 77s 10ms/step - loss: 1.2609 - acc: 0.4208 - val_loss: 1.2230 - val_acc: 0.4419\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 72s 9ms/step - loss: 1.2074 - acc: 0.4568 - val_loss: 1.2095 - val_acc: 0.4488\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 71s 9ms/step - loss: 1.1945 - acc: 0.4591 - val_loss: 1.1953 - val_acc: 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 10/230 [23:35<10:29:27, 171.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 45s 10ms/step - loss: 1.2468 - acc: 0.4304 - val_loss: 1.2187 - val_acc: 0.4458\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 37s 10ms/step - loss: 1.1994 - acc: 0.4580 - val_loss: 1.1999 - val_acc: 0.4491\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 37s 10ms/step - loss: 1.1843 - acc: 0.4658 - val_loss: 1.1866 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 11/230 [25:35<9:28:01, 155.63s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 75s 10ms/step - loss: 1.2822 - acc: 0.4125 - val_loss: 1.2607 - val_acc: 0.4325\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 70s 9ms/step - loss: 1.2337 - acc: 0.4464 - val_loss: 1.2292 - val_acc: 0.4403\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 75s 10ms/step - loss: 1.2141 - acc: 0.4542 - val_loss: 1.2153 - val_acc: 0.4450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 12/230 [29:17<10:38:51, 175.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 50s 9ms/step - loss: 1.2376 - acc: 0.4377 - val_loss: 1.2054 - val_acc: 0.4519\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 50s 10ms/step - loss: 1.1941 - acc: 0.4587 - val_loss: 1.1928 - val_acc: 0.4581\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 62s 12ms/step - loss: 1.1838 - acc: 0.4673 - val_loss: 1.1839 - val_acc: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 13/230 [32:01<10:23:05, 172.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 58s 10ms/step - loss: 1.2522 - acc: 0.4393 - val_loss: 1.2183 - val_acc: 0.4470\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 51s 10ms/step - loss: 1.2061 - acc: 0.4595 - val_loss: 1.2138 - val_acc: 0.4449\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 54s 11ms/step - loss: 1.1949 - acc: 0.4618 - val_loss: 1.1963 - val_acc: 0.4534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 14/230 [34:45<10:11:41, 169.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 45s 10ms/step - loss: 1.2816 - acc: 0.4078 - val_loss: 1.2428 - val_acc: 0.4366\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 36s 10ms/step - loss: 1.2264 - acc: 0.4517 - val_loss: 1.2251 - val_acc: 0.4441\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 37s 10ms/step - loss: 1.2116 - acc: 0.4579 - val_loss: 1.2139 - val_acc: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 15/230 [36:44<9:13:56, 154.59s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.2790 - acc: 0.4134 - val_loss: 1.2374 - val_acc: 0.4394\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2169 - acc: 0.4573 - val_loss: 1.2126 - val_acc: 0.4491\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1970 - acc: 0.4617 - val_loss: 1.1962 - val_acc: 0.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 16/230 [37:32<7:16:24, 122.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.3007 - acc: 0.4039 - val_loss: 1.2804 - val_acc: 0.3993\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.2462 - acc: 0.4372 - val_loss: 1.2376 - val_acc: 0.4395\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2226 - acc: 0.4520 - val_loss: 1.2227 - val_acc: 0.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 17/230 [38:04<5:37:45, 95.14s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2331 - acc: 0.4450 - val_loss: 1.2019 - val_acc: 0.4519\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.1913 - acc: 0.4626 - val_loss: 1.2073 - val_acc: 0.4430\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1834 - acc: 0.4643 - val_loss: 1.1858 - val_acc: 0.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 18/230 [38:36<4:29:08, 76.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3219 - acc: 0.3957 - val_loss: 1.3134 - val_acc: 0.3989\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2997 - acc: 0.4038 - val_loss: 1.2969 - val_acc: 0.3989\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2755 - acc: 0.4089 - val_loss: 1.2695 - val_acc: 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 19/230 [39:41<4:16:00, 72.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.2227 - acc: 0.4456 - val_loss: 1.2121 - val_acc: 0.4484\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.1891 - acc: 0.4614 - val_loss: 1.1886 - val_acc: 0.4604\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.1823 - acc: 0.4644 - val_loss: 1.1917 - val_acc: 0.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▊         | 20/230 [40:54<4:15:56, 73.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2504 - acc: 0.4361 - val_loss: 1.2306 - val_acc: 0.4392\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2052 - acc: 0.4528 - val_loss: 1.2021 - val_acc: 0.4526\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1894 - acc: 0.4627 - val_loss: 1.1902 - val_acc: 0.4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 21/230 [41:28<3:32:56, 61.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.3046 - acc: 0.3937 - val_loss: 1.2742 - val_acc: 0.4088\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2476 - acc: 0.4304 - val_loss: 1.2383 - val_acc: 0.4317\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2274 - acc: 0.4457 - val_loss: 1.2271 - val_acc: 0.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 22/230 [42:16<3:18:27, 57.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2445 - acc: 0.4379 - val_loss: 1.2339 - val_acc: 0.4250\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1981 - acc: 0.4603 - val_loss: 1.1954 - val_acc: 0.4540\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1887 - acc: 0.4627 - val_loss: 1.1929 - val_acc: 0.4534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 23/230 [42:51<2:54:56, 50.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2484 - acc: 0.4321 - val_loss: 1.2129 - val_acc: 0.4485\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.1946 - acc: 0.4646 - val_loss: 1.2014 - val_acc: 0.4560\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1826 - acc: 0.4694 - val_loss: 1.1861 - val_acc: 0.4604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 24/230 [43:23<2:34:54, 45.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.2535 - acc: 0.4269 - val_loss: 1.2092 - val_acc: 0.4441\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1970 - acc: 0.4574 - val_loss: 1.1906 - val_acc: 0.4510\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1875 - acc: 0.4640 - val_loss: 1.1876 - val_acc: 0.4523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 25/230 [44:13<2:39:01, 46.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2507 - acc: 0.4266 - val_loss: 1.2163 - val_acc: 0.4487\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2033 - acc: 0.4568 - val_loss: 1.2191 - val_acc: 0.4491\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1905 - acc: 0.4649 - val_loss: 1.1913 - val_acc: 0.4578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█▏        | 26/230 [44:57<2:35:29, 45.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2517 - acc: 0.4280 - val_loss: 1.2251 - val_acc: 0.4407\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2030 - acc: 0.4572 - val_loss: 1.2033 - val_acc: 0.4484\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1849 - acc: 0.4687 - val_loss: 1.1959 - val_acc: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 27/230 [45:30<2:22:08, 42.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2500 - acc: 0.4271 - val_loss: 1.2211 - val_acc: 0.4461\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2061 - acc: 0.4557 - val_loss: 1.2146 - val_acc: 0.4453\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1909 - acc: 0.4640 - val_loss: 1.1898 - val_acc: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 28/230 [46:15<2:24:02, 42.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2374 - acc: 0.4344 - val_loss: 1.2067 - val_acc: 0.4487\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1943 - acc: 0.4593 - val_loss: 1.1920 - val_acc: 0.4574\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1838 - acc: 0.4663 - val_loss: 1.1892 - val_acc: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 29/230 [47:22<2:47:10, 49.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2441 - acc: 0.4293 - val_loss: 1.2537 - val_acc: 0.4339\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2001 - acc: 0.4548 - val_loss: 1.1925 - val_acc: 0.4580\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.1872 - acc: 0.4647 - val_loss: 1.1862 - val_acc: 0.4588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 30/230 [48:36<3:10:57, 57.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2509 - acc: 0.4296 - val_loss: 1.2210 - val_acc: 0.4432\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2025 - acc: 0.4568 - val_loss: 1.2061 - val_acc: 0.4500\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1883 - acc: 0.4673 - val_loss: 1.1917 - val_acc: 0.4580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 31/230 [49:44<3:20:23, 60.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2238 - acc: 0.4436 - val_loss: 1.1892 - val_acc: 0.4571\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1917 - acc: 0.4623 - val_loss: 1.1924 - val_acc: 0.4609\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1845 - acc: 0.4620 - val_loss: 1.1893 - val_acc: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 32/230 [50:50<3:24:41, 62.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2524 - acc: 0.4366 - val_loss: 1.2203 - val_acc: 0.4474\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2048 - acc: 0.4593 - val_loss: 1.2176 - val_acc: 0.4450\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1931 - acc: 0.4645 - val_loss: 1.1936 - val_acc: 0.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 33/230 [52:00<3:31:43, 64.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2716 - acc: 0.4185 - val_loss: 1.2310 - val_acc: 0.4419\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2118 - acc: 0.4542 - val_loss: 1.2098 - val_acc: 0.4488\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1967 - acc: 0.4582 - val_loss: 1.1981 - val_acc: 0.4539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▍        | 34/230 [53:05<3:31:20, 64.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2432 - acc: 0.4366 - val_loss: 1.2079 - val_acc: 0.4505\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1961 - acc: 0.4593 - val_loss: 1.1948 - val_acc: 0.4548\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1848 - acc: 0.4676 - val_loss: 1.1822 - val_acc: 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 35/230 [54:11<3:31:39, 65.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2375 - acc: 0.4426 - val_loss: 1.2029 - val_acc: 0.4520\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1928 - acc: 0.4595 - val_loss: 1.1928 - val_acc: 0.4522\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1839 - acc: 0.4620 - val_loss: 1.1886 - val_acc: 0.4595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 36/230 [54:56<3:11:23, 59.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2226 - acc: 0.4439 - val_loss: 1.2018 - val_acc: 0.4488\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1912 - acc: 0.4627 - val_loss: 1.1969 - val_acc: 0.4508\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1843 - acc: 0.4676 - val_loss: 1.1898 - val_acc: 0.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 37/230 [55:42<2:57:02, 55.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2254 - acc: 0.4444 - val_loss: 1.2007 - val_acc: 0.4529\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1935 - acc: 0.4587 - val_loss: 1.1921 - val_acc: 0.4586\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1865 - acc: 0.4618 - val_loss: 1.1880 - val_acc: 0.4598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 38/230 [56:44<3:02:50, 57.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.2304 - acc: 0.4434 - val_loss: 1.2425 - val_acc: 0.4456\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1985 - acc: 0.4593 - val_loss: 1.1882 - val_acc: 0.4603\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1891 - acc: 0.4644 - val_loss: 1.1935 - val_acc: 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 39/230 [57:34<2:54:49, 54.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 14s 3ms/step - loss: 1.2275 - acc: 0.4456 - val_loss: 1.2071 - val_acc: 0.4468\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1938 - acc: 0.4580 - val_loss: 1.1984 - val_acc: 0.4449\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1860 - acc: 0.4612 - val_loss: 1.1869 - val_acc: 0.4563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 40/230 [58:12<2:38:34, 50.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2932 - acc: 0.4035 - val_loss: 1.2771 - val_acc: 0.4002\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2490 - acc: 0.4223 - val_loss: 1.2386 - val_acc: 0.4282\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2218 - acc: 0.4508 - val_loss: 1.2232 - val_acc: 0.4415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 41/230 [58:48<2:23:55, 45.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2301 - acc: 0.4427 - val_loss: 1.2097 - val_acc: 0.4478\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1897 - acc: 0.4653 - val_loss: 1.1978 - val_acc: 0.4548\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1787 - acc: 0.4685 - val_loss: 1.1841 - val_acc: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 42/230 [59:21<2:11:37, 42.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2192 - acc: 0.4472 - val_loss: 1.1934 - val_acc: 0.4565\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1883 - acc: 0.4637 - val_loss: 1.1868 - val_acc: 0.4594\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1811 - acc: 0.4696 - val_loss: 1.1925 - val_acc: 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▊        | 43/230 [1:00:25<2:31:25, 48.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2506 - acc: 0.4305 - val_loss: 1.2268 - val_acc: 0.4375\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2113 - acc: 0.4552 - val_loss: 1.2151 - val_acc: 0.4447\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1989 - acc: 0.4583 - val_loss: 1.2010 - val_acc: 0.4507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 44/230 [1:00:57<2:15:04, 43.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2224 - acc: 0.4458 - val_loss: 1.2148 - val_acc: 0.4423\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1958 - acc: 0.4616 - val_loss: 1.2114 - val_acc: 0.4439\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1902 - acc: 0.4610 - val_loss: 1.1918 - val_acc: 0.4533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 45/230 [1:01:29<2:03:38, 40.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2554 - acc: 0.4243 - val_loss: 1.2260 - val_acc: 0.4363\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2085 - acc: 0.4550 - val_loss: 1.2059 - val_acc: 0.4470\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1921 - acc: 0.4654 - val_loss: 1.1955 - val_acc: 0.4555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 46/230 [1:02:29<2:20:57, 45.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2534 - acc: 0.4307 - val_loss: 1.2284 - val_acc: 0.4406\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2083 - acc: 0.4546 - val_loss: 1.2048 - val_acc: 0.4478\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1941 - acc: 0.4609 - val_loss: 1.1956 - val_acc: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 47/230 [1:03:02<2:08:53, 42.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.3329 - acc: 0.3733 - val_loss: 1.2840 - val_acc: 0.3993\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2569 - acc: 0.4210 - val_loss: 1.2513 - val_acc: 0.4282\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2352 - acc: 0.4424 - val_loss: 1.2363 - val_acc: 0.4343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 48/230 [1:03:33<1:58:01, 38.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2456 - acc: 0.4395 - val_loss: 1.2164 - val_acc: 0.4479\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1987 - acc: 0.4595 - val_loss: 1.2011 - val_acc: 0.4517\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1864 - acc: 0.4667 - val_loss: 1.1899 - val_acc: 0.4595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██▏       | 49/230 [1:04:07<1:52:55, 37.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.3211 - acc: 0.3858 - val_loss: 1.3050 - val_acc: 0.3989\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2889 - acc: 0.4037 - val_loss: 1.2878 - val_acc: 0.3990\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2684 - acc: 0.4145 - val_loss: 1.2654 - val_acc: 0.4233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 50/230 [1:04:40<1:47:49, 35.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.2206 - acc: 0.4500 - val_loss: 1.2395 - val_acc: 0.4371\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1883 - acc: 0.4651 - val_loss: 1.1844 - val_acc: 0.4554\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1802 - acc: 0.4704 - val_loss: 1.1961 - val_acc: 0.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 51/230 [1:05:30<2:00:04, 40.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2410 - acc: 0.4372 - val_loss: 1.2113 - val_acc: 0.4481\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1916 - acc: 0.4598 - val_loss: 1.1901 - val_acc: 0.4627\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1816 - acc: 0.4669 - val_loss: 1.1844 - val_acc: 0.4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 52/230 [1:06:32<2:18:11, 46.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2443 - acc: 0.4338 - val_loss: 1.2127 - val_acc: 0.4487\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1981 - acc: 0.4642 - val_loss: 1.1977 - val_acc: 0.4543\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 2ms/step - loss: 1.1851 - acc: 0.4680 - val_loss: 1.1884 - val_acc: 0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 53/230 [1:07:14<2:13:28, 45.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 14s 2ms/step - loss: 1.3248 - acc: 0.3627 - val_loss: 1.2885 - val_acc: 0.3995\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 12s 2ms/step - loss: 1.2578 - acc: 0.4084 - val_loss: 1.2511 - val_acc: 0.4126\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 12s 2ms/step - loss: 1.2337 - acc: 0.4355 - val_loss: 1.2363 - val_acc: 0.4349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 54/230 [1:07:53<2:07:09, 43.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2346 - acc: 0.4407 - val_loss: 1.2085 - val_acc: 0.4462\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 12s 2ms/step - loss: 1.1929 - acc: 0.4642 - val_loss: 1.1983 - val_acc: 0.4542\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 2ms/step - loss: 1.1829 - acc: 0.4642 - val_loss: 1.1896 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 55/230 [1:08:32<2:03:17, 42.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2901 - acc: 0.4109 - val_loss: 1.2509 - val_acc: 0.4247\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.2255 - acc: 0.4486 - val_loss: 1.2183 - val_acc: 0.4452\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.2074 - acc: 0.4544 - val_loss: 1.2075 - val_acc: 0.4517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 56/230 [1:09:02<1:52:00, 38.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2494 - acc: 0.4376 - val_loss: 1.2233 - val_acc: 0.4447\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2004 - acc: 0.4590 - val_loss: 1.1957 - val_acc: 0.4525\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1870 - acc: 0.4682 - val_loss: 1.1936 - val_acc: 0.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▍       | 57/230 [1:09:46<1:56:02, 40.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.3065 - acc: 0.3885 - val_loss: 1.2782 - val_acc: 0.3990\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 2ms/step - loss: 1.2515 - acc: 0.4073 - val_loss: 1.2467 - val_acc: 0.4161\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 12s 2ms/step - loss: 1.2298 - acc: 0.4385 - val_loss: 1.2324 - val_acc: 0.4325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 58/230 [1:10:26<1:54:20, 39.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 15s 2ms/step - loss: 1.2347 - acc: 0.4363 - val_loss: 1.2066 - val_acc: 0.4528\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1916 - acc: 0.4597 - val_loss: 1.1980 - val_acc: 0.4488\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1807 - acc: 0.4674 - val_loss: 1.1823 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 59/230 [1:11:07<1:55:07, 40.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2227 - acc: 0.4457 - val_loss: 1.2085 - val_acc: 0.4508\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1915 - acc: 0.4611 - val_loss: 1.1954 - val_acc: 0.4555\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1863 - acc: 0.4657 - val_loss: 1.1928 - val_acc: 0.4555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 60/230 [1:11:50<1:56:30, 41.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2177 - acc: 0.4487 - val_loss: 1.1935 - val_acc: 0.4497\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1826 - acc: 0.4644 - val_loss: 1.1809 - val_acc: 0.4612\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1711 - acc: 0.4709 - val_loss: 1.1806 - val_acc: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 61/230 [1:12:20<1:46:53, 37.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2568 - acc: 0.4308 - val_loss: 1.2235 - val_acc: 0.4473\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2076 - acc: 0.4554 - val_loss: 1.2106 - val_acc: 0.4488\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1901 - acc: 0.4614 - val_loss: 1.1868 - val_acc: 0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 62/230 [1:13:05<1:51:23, 39.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 2ms/step - loss: 1.2822 - acc: 0.3996 - val_loss: 1.2539 - val_acc: 0.4090\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.2330 - acc: 0.4329 - val_loss: 1.2253 - val_acc: 0.4406\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.2115 - acc: 0.4565 - val_loss: 1.2114 - val_acc: 0.4438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 63/230 [1:13:34<1:41:48, 36.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2354 - acc: 0.4428 - val_loss: 1.2036 - val_acc: 0.4519\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1922 - acc: 0.4611 - val_loss: 1.1879 - val_acc: 0.4577\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1829 - acc: 0.4685 - val_loss: 1.1845 - val_acc: 0.4681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 64/230 [1:14:33<2:00:19, 43.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2487 - acc: 0.4333 - val_loss: 1.2229 - val_acc: 0.4441\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2029 - acc: 0.4581 - val_loss: 1.2002 - val_acc: 0.4531\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1875 - acc: 0.4652 - val_loss: 1.1858 - val_acc: 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 65/230 [1:15:06<1:50:59, 40.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.2585 - acc: 0.4270 - val_loss: 1.2288 - val_acc: 0.4442\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.2027 - acc: 0.4611 - val_loss: 1.1992 - val_acc: 0.4546\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1864 - acc: 0.4654 - val_loss: 1.1876 - val_acc: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▊       | 66/230 [1:15:50<1:53:10, 41.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2240 - acc: 0.4494 - val_loss: 1.1993 - val_acc: 0.4578\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1912 - acc: 0.4656 - val_loss: 1.1892 - val_acc: 0.4600\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1871 - acc: 0.4648 - val_loss: 1.1852 - val_acc: 0.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 67/230 [1:16:51<2:08:01, 47.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2594 - acc: 0.4284 - val_loss: 1.2203 - val_acc: 0.4442\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2031 - acc: 0.4575 - val_loss: 1.2035 - val_acc: 0.4519\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.1917 - acc: 0.4618 - val_loss: 1.1960 - val_acc: 0.4551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|██▉       | 68/230 [1:17:22<1:54:47, 42.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2342 - acc: 0.4470 - val_loss: 1.2066 - val_acc: 0.4505\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1944 - acc: 0.4613 - val_loss: 1.2005 - val_acc: 0.4505\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.1831 - acc: 0.4640 - val_loss: 1.2001 - val_acc: 0.4474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 69/230 [1:18:31<2:14:48, 50.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2413 - acc: 0.4356 - val_loss: 1.2090 - val_acc: 0.4467\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1960 - acc: 0.4609 - val_loss: 1.2061 - val_acc: 0.4459\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1844 - acc: 0.4625 - val_loss: 1.1805 - val_acc: 0.4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 70/230 [1:19:02<1:59:08, 44.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 20s 2ms/step - loss: 1.2685 - acc: 0.4241 - val_loss: 1.2346 - val_acc: 0.4397\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2153 - acc: 0.4559 - val_loss: 1.2135 - val_acc: 0.4468\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1986 - acc: 0.4627 - val_loss: 1.2013 - val_acc: 0.4526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 71/230 [1:20:00<2:08:31, 48.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2603 - acc: 0.4301 - val_loss: 1.2243 - val_acc: 0.4435\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2038 - acc: 0.4610 - val_loss: 1.2031 - val_acc: 0.4487\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1866 - acc: 0.4633 - val_loss: 1.1950 - val_acc: 0.4502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███▏      | 72/230 [1:20:32<1:54:52, 43.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2209 - acc: 0.4477 - val_loss: 1.2020 - val_acc: 0.4572\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1858 - acc: 0.4622 - val_loss: 1.1808 - val_acc: 0.4639\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1781 - acc: 0.4670 - val_loss: 1.1790 - val_acc: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 73/230 [1:21:33<2:07:27, 48.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 14s 3ms/step - loss: 1.2305 - acc: 0.4421 - val_loss: 1.2152 - val_acc: 0.4551\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1885 - acc: 0.4632 - val_loss: 1.2146 - val_acc: 0.4543\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1824 - acc: 0.4671 - val_loss: 1.1811 - val_acc: 0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 74/230 [1:22:10<1:57:56, 45.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 15s 2ms/step - loss: 1.2379 - acc: 0.4428 - val_loss: 1.2164 - val_acc: 0.4435\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1932 - acc: 0.4630 - val_loss: 1.1955 - val_acc: 0.4546\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1815 - acc: 0.4675 - val_loss: 1.1814 - val_acc: 0.4604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 75/230 [1:22:52<1:54:47, 44.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2280 - acc: 0.4432 - val_loss: 1.2022 - val_acc: 0.4511\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1933 - acc: 0.4613 - val_loss: 1.2069 - val_acc: 0.4478\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1871 - acc: 0.4620 - val_loss: 1.1891 - val_acc: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 76/230 [1:23:23<1:43:08, 40.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2666 - acc: 0.4201 - val_loss: 1.2293 - val_acc: 0.4380\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.2109 - acc: 0.4546 - val_loss: 1.2063 - val_acc: 0.4479\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1933 - acc: 0.4612 - val_loss: 1.1937 - val_acc: 0.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 77/230 [1:24:04<1:43:39, 40.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2508 - acc: 0.4320 - val_loss: 1.2257 - val_acc: 0.4397\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2073 - acc: 0.4549 - val_loss: 1.2013 - val_acc: 0.4525\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1897 - acc: 0.4643 - val_loss: 1.1961 - val_acc: 0.4555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 78/230 [1:24:36<1:36:10, 37.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2187 - acc: 0.4480 - val_loss: 1.1928 - val_acc: 0.4566\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1892 - acc: 0.4643 - val_loss: 1.2098 - val_acc: 0.4447\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1830 - acc: 0.4641 - val_loss: 1.1880 - val_acc: 0.4595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 79/230 [1:25:18<1:38:34, 39.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2248 - acc: 0.4457 - val_loss: 1.1960 - val_acc: 0.4578\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1881 - acc: 0.4614 - val_loss: 1.1931 - val_acc: 0.4609\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1797 - acc: 0.4652 - val_loss: 1.1883 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 80/230 [1:25:50<1:32:36, 37.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.2357 - acc: 0.4402 - val_loss: 1.2110 - val_acc: 0.4467\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2122 - acc: 0.4540 - val_loss: 1.2052 - val_acc: 0.4456\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2068 - acc: 0.4536 - val_loss: 1.2284 - val_acc: 0.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 81/230 [1:26:37<1:39:14, 39.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2259 - acc: 0.4444 - val_loss: 1.1997 - val_acc: 0.4572\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1909 - acc: 0.4616 - val_loss: 1.1946 - val_acc: 0.4560\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1825 - acc: 0.4676 - val_loss: 1.1849 - val_acc: 0.4580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 82/230 [1:27:39<1:55:16, 46.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 20s 3ms/step - loss: 1.2161 - acc: 0.4501 - val_loss: 1.1918 - val_acc: 0.4566\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.1828 - acc: 0.4663 - val_loss: 1.1799 - val_acc: 0.4646\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 20s 4ms/step - loss: 1.1772 - acc: 0.4684 - val_loss: 1.1806 - val_acc: 0.4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 83/230 [1:28:37<2:02:09, 49.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2325 - acc: 0.4402 - val_loss: 1.2158 - val_acc: 0.4432\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1951 - acc: 0.4616 - val_loss: 1.2047 - val_acc: 0.4499\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1867 - acc: 0.4668 - val_loss: 1.1870 - val_acc: 0.4606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 84/230 [1:29:20<1:56:32, 47.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 15s 3ms/step - loss: 1.2322 - acc: 0.4388 - val_loss: 1.2108 - val_acc: 0.4484\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2011 - acc: 0.4629 - val_loss: 1.2148 - val_acc: 0.4407\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1932 - acc: 0.4590 - val_loss: 1.1957 - val_acc: 0.4549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 85/230 [1:30:00<1:50:01, 45.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.2445 - acc: 0.4354 - val_loss: 1.2055 - val_acc: 0.4497\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1954 - acc: 0.4592 - val_loss: 1.1890 - val_acc: 0.4595\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1854 - acc: 0.4662 - val_loss: 1.1909 - val_acc: 0.4531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 86/230 [1:30:45<1:49:00, 45.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2851 - acc: 0.4074 - val_loss: 1.2571 - val_acc: 0.4255\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2317 - acc: 0.4499 - val_loss: 1.2280 - val_acc: 0.4400\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2130 - acc: 0.4586 - val_loss: 1.2141 - val_acc: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 87/230 [1:31:47<1:59:52, 50.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2168 - acc: 0.4491 - val_loss: 1.1970 - val_acc: 0.4523\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1863 - acc: 0.4623 - val_loss: 1.1818 - val_acc: 0.4594\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1743 - acc: 0.4716 - val_loss: 1.1896 - val_acc: 0.4562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 88/230 [1:32:32<1:55:25, 48.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2567 - acc: 0.4263 - val_loss: 1.2208 - val_acc: 0.4470\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2051 - acc: 0.4587 - val_loss: 1.2075 - val_acc: 0.4456\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1929 - acc: 0.4623 - val_loss: 1.1938 - val_acc: 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▊      | 89/230 [1:33:05<1:43:28, 44.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2992 - acc: 0.4026 - val_loss: 1.2575 - val_acc: 0.4303\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2365 - acc: 0.4409 - val_loss: 1.2354 - val_acc: 0.4355\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.2204 - acc: 0.4523 - val_loss: 1.2224 - val_acc: 0.4435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 90/230 [1:33:37<1:34:34, 40.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2499 - acc: 0.4342 - val_loss: 1.2197 - val_acc: 0.4452\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2014 - acc: 0.4570 - val_loss: 1.1961 - val_acc: 0.4575\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1859 - acc: 0.4649 - val_loss: 1.1855 - val_acc: 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|███▉      | 91/230 [1:34:10<1:28:44, 38.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2513 - acc: 0.4343 - val_loss: 1.2308 - val_acc: 0.4421\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2046 - acc: 0.4582 - val_loss: 1.2065 - val_acc: 0.4484\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.1916 - acc: 0.4622 - val_loss: 1.1961 - val_acc: 0.4514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 92/230 [1:35:21<1:50:26, 48.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.2377 - acc: 0.4398 - val_loss: 1.2491 - val_acc: 0.4374\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1955 - acc: 0.4629 - val_loss: 1.1912 - val_acc: 0.4589\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1859 - acc: 0.4677 - val_loss: 1.2040 - val_acc: 0.4510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 93/230 [1:36:12<1:51:23, 48.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 14s 3ms/step - loss: 1.2233 - acc: 0.4457 - val_loss: 1.1985 - val_acc: 0.4488\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1916 - acc: 0.4627 - val_loss: 1.1914 - val_acc: 0.4560\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1832 - acc: 0.4627 - val_loss: 1.1870 - val_acc: 0.4614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████      | 94/230 [1:36:47<1:41:23, 44.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 27s 3ms/step - loss: 1.2352 - acc: 0.4455 - val_loss: 1.2060 - val_acc: 0.4484\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.1964 - acc: 0.4613 - val_loss: 1.2016 - val_acc: 0.4560\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.1844 - acc: 0.4697 - val_loss: 1.1896 - val_acc: 0.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████▏     | 95/230 [1:38:03<2:02:05, 54.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2921 - acc: 0.4032 - val_loss: 1.2686 - val_acc: 0.4247\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2481 - acc: 0.4363 - val_loss: 1.2436 - val_acc: 0.4337\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2301 - acc: 0.4492 - val_loss: 1.2321 - val_acc: 0.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 96/230 [1:38:37<1:47:33, 48.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2195 - acc: 0.4479 - val_loss: 1.1998 - val_acc: 0.4479\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1949 - acc: 0.4599 - val_loss: 1.1963 - val_acc: 0.4508\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1882 - acc: 0.4625 - val_loss: 1.1873 - val_acc: 0.4580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 97/230 [1:39:12<1:37:28, 43.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.3112 - acc: 0.3666 - val_loss: 1.2654 - val_acc: 0.4119\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2391 - acc: 0.4349 - val_loss: 1.2283 - val_acc: 0.4401\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2170 - acc: 0.4517 - val_loss: 1.2164 - val_acc: 0.4461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 98/230 [1:40:17<1:50:44, 50.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2307 - acc: 0.4414 - val_loss: 1.2138 - val_acc: 0.4447\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1891 - acc: 0.4642 - val_loss: 1.1975 - val_acc: 0.4560\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.1831 - acc: 0.4676 - val_loss: 1.1859 - val_acc: 0.4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 99/230 [1:41:26<2:02:07, 55.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2372 - acc: 0.4377 - val_loss: 1.2133 - val_acc: 0.4462\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1932 - acc: 0.4610 - val_loss: 1.1930 - val_acc: 0.4520\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1829 - acc: 0.4661 - val_loss: 1.1839 - val_acc: 0.4591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 100/230 [1:42:27<2:04:49, 57.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2606 - acc: 0.4295 - val_loss: 1.2166 - val_acc: 0.4462\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2011 - acc: 0.4593 - val_loss: 1.2003 - val_acc: 0.4526\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1878 - acc: 0.4633 - val_loss: 1.1879 - val_acc: 0.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 101/230 [1:43:13<1:56:01, 53.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 27s 3ms/step - loss: 1.2313 - acc: 0.4411 - val_loss: 1.2059 - val_acc: 0.4528\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2018 - acc: 0.4560 - val_loss: 1.2206 - val_acc: 0.4481\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.1910 - acc: 0.4633 - val_loss: 1.2029 - val_acc: 0.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 102/230 [1:44:30<2:09:59, 60.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2612 - acc: 0.4267 - val_loss: 1.2378 - val_acc: 0.4383\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.2191 - acc: 0.4513 - val_loss: 1.2154 - val_acc: 0.4479\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2044 - acc: 0.4592 - val_loss: 1.2041 - val_acc: 0.4534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▍     | 103/230 [1:45:01<1:50:16, 52.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2373 - acc: 0.4377 - val_loss: 1.2129 - val_acc: 0.4450\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1966 - acc: 0.4598 - val_loss: 1.1947 - val_acc: 0.4528\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1856 - acc: 0.4667 - val_loss: 1.1856 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 104/230 [1:45:36<1:38:15, 46.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2246 - acc: 0.4439 - val_loss: 1.2117 - val_acc: 0.4499\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1910 - acc: 0.4634 - val_loss: 1.1927 - val_acc: 0.4580\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1820 - acc: 0.4672 - val_loss: 1.1940 - val_acc: 0.4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 105/230 [1:46:42<1:49:43, 52.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2928 - acc: 0.4054 - val_loss: 1.2626 - val_acc: 0.4158\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2314 - acc: 0.4463 - val_loss: 1.2250 - val_acc: 0.4423\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2099 - acc: 0.4556 - val_loss: 1.2114 - val_acc: 0.4473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 106/230 [1:47:28<1:44:24, 50.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.2443 - acc: 0.4302 - val_loss: 1.2129 - val_acc: 0.4461\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2002 - acc: 0.4580 - val_loss: 1.2139 - val_acc: 0.4363\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1899 - acc: 0.4636 - val_loss: 1.1871 - val_acc: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 107/230 [1:48:16<1:42:25, 49.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2807 - acc: 0.4126 - val_loss: 1.2508 - val_acc: 0.4363\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2231 - acc: 0.4493 - val_loss: 1.2160 - val_acc: 0.4441\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2021 - acc: 0.4585 - val_loss: 1.1994 - val_acc: 0.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 108/230 [1:49:18<1:48:24, 53.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2674 - acc: 0.4168 - val_loss: 1.2278 - val_acc: 0.4380\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2110 - acc: 0.4544 - val_loss: 1.2078 - val_acc: 0.4478\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1966 - acc: 0.4614 - val_loss: 1.1984 - val_acc: 0.4499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 109/230 [1:50:00<1:41:10, 50.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2294 - acc: 0.4394 - val_loss: 1.2066 - val_acc: 0.4479\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2016 - acc: 0.4561 - val_loss: 1.2122 - val_acc: 0.4415\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1951 - acc: 0.4591 - val_loss: 1.1973 - val_acc: 0.4526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 110/230 [1:50:48<1:38:32, 49.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2227 - acc: 0.4413 - val_loss: 1.2112 - val_acc: 0.4476\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1941 - acc: 0.4620 - val_loss: 1.2557 - val_acc: 0.4097\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.1860 - acc: 0.4639 - val_loss: 1.1806 - val_acc: 0.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 111/230 [1:51:35<1:36:45, 48.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2814 - acc: 0.4159 - val_loss: 1.2529 - val_acc: 0.4219\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2274 - acc: 0.4489 - val_loss: 1.2218 - val_acc: 0.4432\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2109 - acc: 0.4541 - val_loss: 1.2152 - val_acc: 0.4403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▊     | 112/230 [1:52:38<1:43:59, 52.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2365 - acc: 0.4383 - val_loss: 1.2257 - val_acc: 0.4426\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1965 - acc: 0.4618 - val_loss: 1.2048 - val_acc: 0.4491\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1825 - acc: 0.4674 - val_loss: 1.2022 - val_acc: 0.4490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 113/230 [1:53:13<1:33:09, 47.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2261 - acc: 0.4453 - val_loss: 1.1997 - val_acc: 0.4542\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1849 - acc: 0.4692 - val_loss: 1.1859 - val_acc: 0.4601\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1725 - acc: 0.4729 - val_loss: 1.1843 - val_acc: 0.4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|████▉     | 114/230 [1:54:19<1:42:30, 53.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2383 - acc: 0.4389 - val_loss: 1.2144 - val_acc: 0.4488\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.1973 - acc: 0.4622 - val_loss: 1.1960 - val_acc: 0.4591\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1859 - acc: 0.4641 - val_loss: 1.1871 - val_acc: 0.4604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 115/230 [1:54:51<1:29:36, 46.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2306 - acc: 0.4416 - val_loss: 1.2001 - val_acc: 0.4545\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.1886 - acc: 0.4610 - val_loss: 1.1888 - val_acc: 0.4539\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1815 - acc: 0.4651 - val_loss: 1.1793 - val_acc: 0.4639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 116/230 [1:56:00<1:41:33, 53.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.2509 - acc: 0.4238 - val_loss: 1.2186 - val_acc: 0.4433\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2003 - acc: 0.4615 - val_loss: 1.2060 - val_acc: 0.4508\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1871 - acc: 0.4652 - val_loss: 1.1901 - val_acc: 0.4562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 117/230 [1:56:49<1:38:14, 52.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2192 - acc: 0.4498 - val_loss: 1.1969 - val_acc: 0.4528\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1868 - acc: 0.4630 - val_loss: 1.1916 - val_acc: 0.4581\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1752 - acc: 0.4712 - val_loss: 1.2029 - val_acc: 0.4542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████▏    | 118/230 [1:57:55<1:45:03, 56.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2718 - acc: 0.4182 - val_loss: 1.2341 - val_acc: 0.4371\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2181 - acc: 0.4542 - val_loss: 1.2159 - val_acc: 0.4456\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2025 - acc: 0.4607 - val_loss: 1.2036 - val_acc: 0.4499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 119/230 [1:58:58<1:47:38, 58.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2351 - acc: 0.4427 - val_loss: 1.2111 - val_acc: 0.4464\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1923 - acc: 0.4595 - val_loss: 1.1979 - val_acc: 0.4546\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1827 - acc: 0.4688 - val_loss: 1.1962 - val_acc: 0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 120/230 [1:59:31<1:33:01, 50.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 21s 4ms/step - loss: 1.2440 - acc: 0.4333 - val_loss: 1.2006 - val_acc: 0.4529\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 18s 4ms/step - loss: 1.1966 - acc: 0.4567 - val_loss: 1.2000 - val_acc: 0.4543\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 18s 4ms/step - loss: 1.1853 - acc: 0.4623 - val_loss: 1.1927 - val_acc: 0.4517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 121/230 [2:00:29<1:35:58, 52.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2485 - acc: 0.4340 - val_loss: 1.2159 - val_acc: 0.4438\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1997 - acc: 0.4595 - val_loss: 1.1982 - val_acc: 0.4502\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1870 - acc: 0.4646 - val_loss: 1.1897 - val_acc: 0.4569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 122/230 [2:01:37<1:43:09, 57.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2338 - acc: 0.4432 - val_loss: 1.1979 - val_acc: 0.4545\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2049 - acc: 0.4594 - val_loss: 1.1963 - val_acc: 0.4543\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1974 - acc: 0.4591 - val_loss: 1.1978 - val_acc: 0.4508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 123/230 [2:02:46<1:48:34, 60.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2518 - acc: 0.4290 - val_loss: 1.2153 - val_acc: 0.4450\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.2016 - acc: 0.4574 - val_loss: 1.1993 - val_acc: 0.4542\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1869 - acc: 0.4665 - val_loss: 1.1916 - val_acc: 0.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 124/230 [2:03:45<1:46:37, 60.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2512 - acc: 0.4328 - val_loss: 1.2234 - val_acc: 0.4418\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2050 - acc: 0.4564 - val_loss: 1.2082 - val_acc: 0.4508\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1896 - acc: 0.4627 - val_loss: 1.2001 - val_acc: 0.4508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 125/230 [2:04:30<1:37:27, 55.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2368 - acc: 0.4400 - val_loss: 1.2067 - val_acc: 0.4500\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1924 - acc: 0.4615 - val_loss: 1.1982 - val_acc: 0.4548\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1825 - acc: 0.4656 - val_loss: 1.1902 - val_acc: 0.4555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▍    | 126/230 [2:05:03<1:24:45, 48.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2526 - acc: 0.4282 - val_loss: 1.2290 - val_acc: 0.4397\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2077 - acc: 0.4572 - val_loss: 1.2051 - val_acc: 0.4514\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1922 - acc: 0.4639 - val_loss: 1.1952 - val_acc: 0.4551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 127/230 [2:06:10<1:33:22, 54.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2258 - acc: 0.4421 - val_loss: 1.2097 - val_acc: 0.4433\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1927 - acc: 0.4606 - val_loss: 1.1906 - val_acc: 0.4586\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.1863 - acc: 0.4642 - val_loss: 1.1854 - val_acc: 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 128/230 [2:06:43<1:21:49, 48.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.3033 - acc: 0.3822 - val_loss: 1.2704 - val_acc: 0.4070\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2438 - acc: 0.4380 - val_loss: 1.2390 - val_acc: 0.4383\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2234 - acc: 0.4520 - val_loss: 1.2251 - val_acc: 0.4419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 129/230 [2:07:30<1:19:59, 47.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2185 - acc: 0.4458 - val_loss: 1.2075 - val_acc: 0.4491\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1916 - acc: 0.4623 - val_loss: 1.1893 - val_acc: 0.4595\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1853 - acc: 0.4630 - val_loss: 1.1899 - val_acc: 0.4581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 130/230 [2:08:06<1:13:54, 44.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 21s 4ms/step - loss: 1.2283 - acc: 0.4410 - val_loss: 1.1972 - val_acc: 0.4569\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 18s 4ms/step - loss: 1.1904 - acc: 0.4633 - val_loss: 1.2222 - val_acc: 0.4291\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 18s 4ms/step - loss: 1.1835 - acc: 0.4639 - val_loss: 1.1805 - val_acc: 0.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 131/230 [2:09:03<1:19:23, 48.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2658 - acc: 0.4157 - val_loss: 1.2332 - val_acc: 0.4378\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2154 - acc: 0.4535 - val_loss: 1.2200 - val_acc: 0.4423\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2015 - acc: 0.4591 - val_loss: 1.2041 - val_acc: 0.4508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 132/230 [2:09:49<1:17:09, 47.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2193 - acc: 0.4476 - val_loss: 1.2021 - val_acc: 0.4543\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.1922 - acc: 0.4616 - val_loss: 1.2269 - val_acc: 0.4430\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.1836 - acc: 0.4654 - val_loss: 1.1867 - val_acc: 0.4633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 133/230 [2:11:02<1:28:54, 55.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.3116 - acc: 0.3901 - val_loss: 1.3081 - val_acc: 0.3989\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2919 - acc: 0.4038 - val_loss: 1.2920 - val_acc: 0.3989\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2739 - acc: 0.4050 - val_loss: 1.2721 - val_acc: 0.4031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 134/230 [2:12:10<1:34:21, 58.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.2946 - acc: 0.3992 - val_loss: 1.2739 - val_acc: 0.4083\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2457 - acc: 0.4389 - val_loss: 1.2384 - val_acc: 0.4413\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2214 - acc: 0.4528 - val_loss: 1.2216 - val_acc: 0.4432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▊    | 135/230 [2:13:18<1:37:54, 61.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 28s 3ms/step - loss: 1.2155 - acc: 0.4485 - val_loss: 1.1979 - val_acc: 0.4508\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.1842 - acc: 0.4671 - val_loss: 1.1858 - val_acc: 0.4624\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.1747 - acc: 0.4720 - val_loss: 1.1867 - val_acc: 0.4614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 136/230 [2:14:37<1:44:42, 66.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2317 - acc: 0.4430 - val_loss: 1.2155 - val_acc: 0.4360\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1905 - acc: 0.4614 - val_loss: 1.1864 - val_acc: 0.4610\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.1820 - acc: 0.4641 - val_loss: 1.2058 - val_acc: 0.4499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████▉    | 137/230 [2:15:48<1:45:23, 68.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 15s 3ms/step - loss: 1.2347 - acc: 0.4427 - val_loss: 1.1969 - val_acc: 0.4540\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.1915 - acc: 0.4589 - val_loss: 1.1875 - val_acc: 0.4537\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 14s 4ms/step - loss: 1.1832 - acc: 0.4659 - val_loss: 1.1817 - val_acc: 0.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 138/230 [2:16:29<1:31:55, 59.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2442 - acc: 0.4421 - val_loss: 1.2172 - val_acc: 0.4455\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1975 - acc: 0.4591 - val_loss: 1.1964 - val_acc: 0.4490\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1854 - acc: 0.4661 - val_loss: 1.1986 - val_acc: 0.4499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 139/230 [2:17:36<1:34:13, 62.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2711 - acc: 0.4188 - val_loss: 1.2383 - val_acc: 0.4390\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2183 - acc: 0.4532 - val_loss: 1.2183 - val_acc: 0.4449\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2035 - acc: 0.4586 - val_loss: 1.2059 - val_acc: 0.4487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████    | 140/230 [2:18:20<1:24:53, 56.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3126 - acc: 0.4049 - val_loss: 1.2748 - val_acc: 0.4102\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2481 - acc: 0.4360 - val_loss: 1.2417 - val_acc: 0.4380\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2273 - acc: 0.4498 - val_loss: 1.2285 - val_acc: 0.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████▏   | 141/230 [2:19:24<1:27:18, 58.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.3110 - acc: 0.4027 - val_loss: 1.2917 - val_acc: 0.3989\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2605 - acc: 0.4151 - val_loss: 1.2459 - val_acc: 0.4323\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2324 - acc: 0.4470 - val_loss: 1.2319 - val_acc: 0.4383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 142/230 [2:20:09<1:20:08, 54.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.3127 - acc: 0.3979 - val_loss: 1.3018 - val_acc: 0.3993\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2763 - acc: 0.4172 - val_loss: 1.2666 - val_acc: 0.4215\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.2491 - acc: 0.4384 - val_loss: 1.2491 - val_acc: 0.4316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 143/230 [2:20:52<1:14:18, 51.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2860 - acc: 0.4218 - val_loss: 1.2375 - val_acc: 0.4394\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2116 - acc: 0.4554 - val_loss: 1.2217 - val_acc: 0.4471\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1932 - acc: 0.4614 - val_loss: 1.1919 - val_acc: 0.4542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 144/230 [2:21:28<1:07:05, 46.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2351 - acc: 0.4381 - val_loss: 1.1949 - val_acc: 0.4525\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1948 - acc: 0.4589 - val_loss: 1.1845 - val_acc: 0.4607\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1826 - acc: 0.4688 - val_loss: 1.1856 - val_acc: 0.4578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 145/230 [2:22:13<1:05:25, 46.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.2564 - acc: 0.4376 - val_loss: 1.2313 - val_acc: 0.4310\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2064 - acc: 0.4593 - val_loss: 1.2162 - val_acc: 0.4488\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1942 - acc: 0.4641 - val_loss: 1.2075 - val_acc: 0.4508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 146/230 [2:23:01<1:05:11, 46.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2471 - acc: 0.4402 - val_loss: 1.2208 - val_acc: 0.4455\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.2018 - acc: 0.4596 - val_loss: 1.1996 - val_acc: 0.4536\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1902 - acc: 0.4618 - val_loss: 1.1991 - val_acc: 0.4549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 147/230 [2:23:44<1:02:54, 45.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2186 - acc: 0.4474 - val_loss: 1.1963 - val_acc: 0.4505\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1857 - acc: 0.4642 - val_loss: 1.1865 - val_acc: 0.4591\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1780 - acc: 0.4687 - val_loss: 1.1858 - val_acc: 0.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 148/230 [2:24:47<1:09:40, 50.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2514 - acc: 0.4319 - val_loss: 1.2289 - val_acc: 0.4433\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2061 - acc: 0.4595 - val_loss: 1.2050 - val_acc: 0.4543\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1911 - acc: 0.4649 - val_loss: 1.1948 - val_acc: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▍   | 149/230 [2:25:18<1:00:34, 44.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2358 - acc: 0.4383 - val_loss: 1.2066 - val_acc: 0.4484\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1945 - acc: 0.4587 - val_loss: 1.1929 - val_acc: 0.4572\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.1815 - acc: 0.4677 - val_loss: 1.1925 - val_acc: 0.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 150/230 [2:25:48<53:47, 40.35s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2308 - acc: 0.4415 - val_loss: 1.2023 - val_acc: 0.4508\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1889 - acc: 0.4641 - val_loss: 1.1890 - val_acc: 0.4639\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1802 - acc: 0.4655 - val_loss: 1.2115 - val_acc: 0.4421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 151/230 [2:26:31<54:10, 41.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.2270 - acc: 0.4440 - val_loss: 1.1999 - val_acc: 0.4546\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1913 - acc: 0.4628 - val_loss: 1.1903 - val_acc: 0.4560\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1800 - acc: 0.4704 - val_loss: 1.1873 - val_acc: 0.4617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 152/230 [2:27:01<49:05, 37.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2329 - acc: 0.4430 - val_loss: 1.2050 - val_acc: 0.4494\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1900 - acc: 0.4612 - val_loss: 1.2031 - val_acc: 0.4551\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1823 - acc: 0.4675 - val_loss: 1.1829 - val_acc: 0.4655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 153/230 [2:27:45<50:48, 39.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3157 - acc: 0.3831 - val_loss: 1.2886 - val_acc: 0.3989\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2614 - acc: 0.4205 - val_loss: 1.2521 - val_acc: 0.4352\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2313 - acc: 0.4512 - val_loss: 1.2297 - val_acc: 0.4413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 154/230 [2:28:45<58:04, 45.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 20s 2ms/step - loss: 1.2327 - acc: 0.4409 - val_loss: 1.2090 - val_acc: 0.4465\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1918 - acc: 0.4608 - val_loss: 1.1879 - val_acc: 0.4540\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1814 - acc: 0.4674 - val_loss: 1.1861 - val_acc: 0.4597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 155/230 [2:29:43<1:01:42, 49.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2621 - acc: 0.4373 - val_loss: 1.2298 - val_acc: 0.4432\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2122 - acc: 0.4593 - val_loss: 1.2109 - val_acc: 0.4504\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.1981 - acc: 0.4606 - val_loss: 1.2006 - val_acc: 0.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 156/230 [2:30:49<1:07:18, 54.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2335 - acc: 0.4395 - val_loss: 1.2120 - val_acc: 0.4430\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1960 - acc: 0.4618 - val_loss: 1.1899 - val_acc: 0.4607\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1842 - acc: 0.4680 - val_loss: 1.1861 - val_acc: 0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 157/230 [2:31:49<1:08:25, 56.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 10s 2ms/step - loss: 1.2364 - acc: 0.4395 - val_loss: 1.2068 - val_acc: 0.4552\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1926 - acc: 0.4617 - val_loss: 1.1904 - val_acc: 0.4551\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1778 - acc: 0.4696 - val_loss: 1.1942 - val_acc: 0.4612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▊   | 158/230 [2:32:19<57:46, 48.14s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2339 - acc: 0.4394 - val_loss: 1.2007 - val_acc: 0.4598\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 18s 2ms/step - loss: 1.1967 - acc: 0.4559 - val_loss: 1.2032 - val_acc: 0.4456\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1898 - acc: 0.4620 - val_loss: 1.1925 - val_acc: 0.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 159/230 [2:33:17<1:00:39, 51.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 20s 2ms/step - loss: 1.2803 - acc: 0.4117 - val_loss: 1.2486 - val_acc: 0.4395\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2291 - acc: 0.4533 - val_loss: 1.2286 - val_acc: 0.4415\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2149 - acc: 0.4561 - val_loss: 1.2173 - val_acc: 0.4439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████▉   | 160/230 [2:34:16<1:02:16, 53.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2507 - acc: 0.4284 - val_loss: 1.2264 - val_acc: 0.4413\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1994 - acc: 0.4590 - val_loss: 1.2037 - val_acc: 0.4552\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1852 - acc: 0.4661 - val_loss: 1.1935 - val_acc: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 161/230 [2:35:00<58:11, 50.60s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2340 - acc: 0.4484 - val_loss: 1.2082 - val_acc: 0.4514\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1956 - acc: 0.4625 - val_loss: 1.1934 - val_acc: 0.4545\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1847 - acc: 0.4696 - val_loss: 1.2243 - val_acc: 0.4526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 162/230 [2:35:32<50:59, 44.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 2ms/step - loss: 1.2786 - acc: 0.4192 - val_loss: 1.2452 - val_acc: 0.4413\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2284 - acc: 0.4520 - val_loss: 1.2266 - val_acc: 0.4441\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.2140 - acc: 0.4568 - val_loss: 1.2156 - val_acc: 0.4473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 163/230 [2:36:03<45:37, 40.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 14s 2ms/step - loss: 1.2564 - acc: 0.4269 - val_loss: 1.2174 - val_acc: 0.4523\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.2025 - acc: 0.4571 - val_loss: 1.1980 - val_acc: 0.4551\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1873 - acc: 0.4661 - val_loss: 1.1926 - val_acc: 0.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████▏  | 164/230 [2:36:44<44:55, 40.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2231 - acc: 0.4437 - val_loss: 1.1958 - val_acc: 0.4537\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 2ms/step - loss: 1.1899 - acc: 0.4628 - val_loss: 1.1864 - val_acc: 0.4659\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 12s 2ms/step - loss: 1.1776 - acc: 0.4728 - val_loss: 1.1886 - val_acc: 0.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 165/230 [2:37:23<43:52, 40.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2261 - acc: 0.4442 - val_loss: 1.1973 - val_acc: 0.4552\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1871 - acc: 0.4649 - val_loss: 1.2134 - val_acc: 0.4415\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1783 - acc: 0.4670 - val_loss: 1.1810 - val_acc: 0.4606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 166/230 [2:37:59<41:34, 38.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2844 - acc: 0.4126 - val_loss: 1.2482 - val_acc: 0.4262\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2277 - acc: 0.4462 - val_loss: 1.2225 - val_acc: 0.4394\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2103 - acc: 0.4544 - val_loss: 1.2125 - val_acc: 0.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 167/230 [2:38:30<38:26, 36.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2542 - acc: 0.4318 - val_loss: 1.2160 - val_acc: 0.4456\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2005 - acc: 0.4576 - val_loss: 1.2095 - val_acc: 0.4487\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1867 - acc: 0.4636 - val_loss: 1.1902 - val_acc: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 168/230 [2:39:02<36:33, 35.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2326 - acc: 0.4434 - val_loss: 1.1994 - val_acc: 0.4536\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1896 - acc: 0.4647 - val_loss: 1.1911 - val_acc: 0.4542\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1791 - acc: 0.4673 - val_loss: 1.1801 - val_acc: 0.4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 169/230 [2:40:02<43:22, 42.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2909 - acc: 0.4084 - val_loss: 1.2483 - val_acc: 0.4377\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2231 - acc: 0.4544 - val_loss: 1.2155 - val_acc: 0.4471\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2019 - acc: 0.4597 - val_loss: 1.2017 - val_acc: 0.4516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 170/230 [2:41:01<47:33, 47.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2687 - acc: 0.4174 - val_loss: 1.2336 - val_acc: 0.4384\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2151 - acc: 0.4551 - val_loss: 1.2143 - val_acc: 0.4458\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1999 - acc: 0.4591 - val_loss: 1.2006 - val_acc: 0.4539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 171/230 [2:41:34<42:26, 43.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.2400 - acc: 0.4438 - val_loss: 1.2075 - val_acc: 0.4528\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.1946 - acc: 0.4615 - val_loss: 1.2104 - val_acc: 0.4427\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.1827 - acc: 0.4660 - val_loss: 1.1834 - val_acc: 0.4603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▍  | 172/230 [2:42:47<50:34, 52.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2635 - acc: 0.4228 - val_loss: 1.2251 - val_acc: 0.4313\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.2121 - acc: 0.4516 - val_loss: 1.2073 - val_acc: 0.4462\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1957 - acc: 0.4559 - val_loss: 1.1931 - val_acc: 0.4589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 173/230 [2:43:47<51:48, 54.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2370 - acc: 0.4376 - val_loss: 1.2089 - val_acc: 0.4488\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1932 - acc: 0.4603 - val_loss: 1.1868 - val_acc: 0.4589\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1797 - acc: 0.4686 - val_loss: 1.1883 - val_acc: 0.4568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 174/230 [2:44:48<52:36, 56.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2705 - acc: 0.4255 - val_loss: 1.2340 - val_acc: 0.4445\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2142 - acc: 0.4574 - val_loss: 1.2099 - val_acc: 0.4494\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.1972 - acc: 0.4635 - val_loss: 1.1971 - val_acc: 0.4537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 175/230 [2:45:20<44:59, 49.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2210 - acc: 0.4419 - val_loss: 1.2068 - val_acc: 0.4467\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1945 - acc: 0.4586 - val_loss: 1.1989 - val_acc: 0.4533\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1874 - acc: 0.4654 - val_loss: 1.1898 - val_acc: 0.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 176/230 [2:46:19<46:56, 52.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2186 - acc: 0.4477 - val_loss: 1.1962 - val_acc: 0.4552\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1862 - acc: 0.4616 - val_loss: 1.1885 - val_acc: 0.4559\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1780 - acc: 0.4676 - val_loss: 1.1870 - val_acc: 0.4549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 177/230 [2:47:02<43:26, 49.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.2347 - acc: 0.4357 - val_loss: 1.2228 - val_acc: 0.4291\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1917 - acc: 0.4578 - val_loss: 1.1917 - val_acc: 0.4559\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1819 - acc: 0.4678 - val_loss: 1.2066 - val_acc: 0.4478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 178/230 [2:47:49<42:09, 48.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2192 - acc: 0.4439 - val_loss: 1.1945 - val_acc: 0.4539\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1915 - acc: 0.4603 - val_loss: 1.1885 - val_acc: 0.4555\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1825 - acc: 0.4667 - val_loss: 1.2171 - val_acc: 0.4450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 179/230 [2:48:21<37:07, 43.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 2ms/step - loss: 1.2776 - acc: 0.4174 - val_loss: 1.2395 - val_acc: 0.4329\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2191 - acc: 0.4518 - val_loss: 1.2158 - val_acc: 0.4427\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2031 - acc: 0.4583 - val_loss: 1.2018 - val_acc: 0.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 180/230 [2:49:20<40:14, 48.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2673 - acc: 0.4167 - val_loss: 1.2201 - val_acc: 0.4436\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.2035 - acc: 0.4589 - val_loss: 1.2028 - val_acc: 0.4575\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1898 - acc: 0.4640 - val_loss: 1.1926 - val_acc: 0.4577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 79%|███████▊  | 181/230 [2:50:19<42:07, 51.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 13s 3ms/step - loss: 1.2290 - acc: 0.4467 - val_loss: 1.2044 - val_acc: 0.4485\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1964 - acc: 0.4579 - val_loss: 1.1957 - val_acc: 0.4549\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1868 - acc: 0.4642 - val_loss: 1.1928 - val_acc: 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 79%|███████▉  | 182/230 [2:50:53<36:55, 46.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2450 - acc: 0.4350 - val_loss: 1.2129 - val_acc: 0.4445\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1973 - acc: 0.4616 - val_loss: 1.2246 - val_acc: 0.4461\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 3ms/step - loss: 1.1851 - acc: 0.4657 - val_loss: 1.2034 - val_acc: 0.4508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|███████▉  | 183/230 [2:51:36<35:27, 45.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.3140 - acc: 0.3871 - val_loss: 1.3069 - val_acc: 0.3998\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 12s 2ms/step - loss: 1.2857 - acc: 0.4064 - val_loss: 1.2845 - val_acc: 0.4047\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 2ms/step - loss: 1.2630 - acc: 0.4206 - val_loss: 1.2649 - val_acc: 0.4170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 184/230 [2:52:15<33:17, 43.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.3018 - acc: 0.4005 - val_loss: 1.2590 - val_acc: 0.4296\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 12s 2ms/step - loss: 1.2335 - acc: 0.4471 - val_loss: 1.2323 - val_acc: 0.4387\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 13s 2ms/step - loss: 1.2171 - acc: 0.4530 - val_loss: 1.2215 - val_acc: 0.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 185/230 [2:52:55<31:42, 42.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2381 - acc: 0.4374 - val_loss: 1.2091 - val_acc: 0.4462\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1953 - acc: 0.4616 - val_loss: 1.1923 - val_acc: 0.4646\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.1823 - acc: 0.4679 - val_loss: 1.1892 - val_acc: 0.4595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 186/230 [2:53:27<28:53, 39.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2675 - acc: 0.4260 - val_loss: 1.2396 - val_acc: 0.4381\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2148 - acc: 0.4544 - val_loss: 1.2152 - val_acc: 0.4462\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2009 - acc: 0.4584 - val_loss: 1.2006 - val_acc: 0.4502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████▏ | 187/230 [2:53:59<26:32, 37.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.2148 - acc: 0.4521 - val_loss: 1.2247 - val_acc: 0.4462\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1843 - acc: 0.4688 - val_loss: 1.1952 - val_acc: 0.4548\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.1778 - acc: 0.4695 - val_loss: 1.1908 - val_acc: 0.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 188/230 [2:55:00<30:54, 44.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2637 - acc: 0.4239 - val_loss: 1.2216 - val_acc: 0.4474\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.2107 - acc: 0.4524 - val_loss: 1.2087 - val_acc: 0.4502\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1985 - acc: 0.4559 - val_loss: 1.1979 - val_acc: 0.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 189/230 [2:55:44<30:10, 44.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2364 - acc: 0.4399 - val_loss: 1.2025 - val_acc: 0.4542\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1920 - acc: 0.4624 - val_loss: 1.1877 - val_acc: 0.4549\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1842 - acc: 0.4650 - val_loss: 1.1813 - val_acc: 0.4598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 190/230 [2:56:30<29:51, 44.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2248 - acc: 0.4443 - val_loss: 1.2071 - val_acc: 0.4464\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1917 - acc: 0.4642 - val_loss: 1.1894 - val_acc: 0.4591\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1844 - acc: 0.4663 - val_loss: 1.1858 - val_acc: 0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 191/230 [2:57:14<28:59, 44.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.3178 - acc: 0.3947 - val_loss: 1.2905 - val_acc: 0.4024\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2689 - acc: 0.4256 - val_loss: 1.2633 - val_acc: 0.4325\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2470 - acc: 0.4439 - val_loss: 1.2468 - val_acc: 0.4415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 192/230 [2:57:46<25:51, 40.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.3239 - acc: 0.3960 - val_loss: 1.2976 - val_acc: 0.3980\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 9s 2ms/step - loss: 1.2606 - acc: 0.4065 - val_loss: 1.2456 - val_acc: 0.4115\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2247 - acc: 0.4378 - val_loss: 1.2224 - val_acc: 0.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 193/230 [2:58:18<23:29, 38.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 21s 2ms/step - loss: 1.2265 - acc: 0.4479 - val_loss: 1.2032 - val_acc: 0.4504\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 19s 2ms/step - loss: 1.1921 - acc: 0.4620 - val_loss: 1.1875 - val_acc: 0.4554\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 19s 3ms/step - loss: 1.1849 - acc: 0.4680 - val_loss: 1.1846 - val_acc: 0.4618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 194/230 [2:59:18<26:44, 44.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.2449 - acc: 0.4333 - val_loss: 1.2301 - val_acc: 0.4310\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 27s 4ms/step - loss: 1.2070 - acc: 0.4550 - val_loss: 1.2255 - val_acc: 0.4093\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 36s 5ms/step - loss: 1.1932 - acc: 0.4593 - val_loss: 1.1827 - val_acc: 0.4591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▍ | 195/230 [3:00:47<33:53, 58.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 68s 12ms/step - loss: 1.2224 - acc: 0.4447 - val_loss: 1.2123 - val_acc: 0.4464\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 54s 11ms/step - loss: 1.1938 - acc: 0.4581 - val_loss: 1.1928 - val_acc: 0.4565\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 53s 10ms/step - loss: 1.1862 - acc: 0.4662 - val_loss: 1.1850 - val_acc: 0.4623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 196/230 [3:03:44<53:02, 93.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 81s 10ms/step - loss: 1.2309 - acc: 0.4455 - val_loss: 1.2020 - val_acc: 0.4574\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 81s 11ms/step - loss: 1.1931 - acc: 0.4665 - val_loss: 1.1902 - val_acc: 0.4577\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 78s 10ms/step - loss: 1.1826 - acc: 0.4677 - val_loss: 1.2103 - val_acc: 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 197/230 [3:07:45<1:15:46, 137.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 84s 10ms/step - loss: 1.2290 - acc: 0.4405 - val_loss: 1.2012 - val_acc: 0.4520\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 76s 10ms/step - loss: 1.1920 - acc: 0.4597 - val_loss: 1.1861 - val_acc: 0.4597\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 79s 10ms/step - loss: 1.1851 - acc: 0.4705 - val_loss: 1.1932 - val_acc: 0.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 198/230 [3:11:45<1:29:55, 168.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 66s 12ms/step - loss: 1.2423 - acc: 0.4339 - val_loss: 1.2136 - val_acc: 0.4516\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 53s 10ms/step - loss: 1.1946 - acc: 0.4587 - val_loss: 1.1906 - val_acc: 0.4589\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 53s 11ms/step - loss: 1.1849 - acc: 0.4678 - val_loss: 1.1960 - val_acc: 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 199/230 [3:14:38<1:27:46, 169.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 62s 12ms/step - loss: 1.2211 - acc: 0.4426 - val_loss: 1.1983 - val_acc: 0.4478\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 65s 13ms/step - loss: 1.1929 - acc: 0.4598 - val_loss: 1.2116 - val_acc: 0.4510\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 60s 12ms/step - loss: 1.1880 - acc: 0.4621 - val_loss: 1.1833 - val_acc: 0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 200/230 [3:17:45<1:27:30, 175.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 102s 13ms/step - loss: 1.2474 - acc: 0.4294 - val_loss: 1.2867 - val_acc: 0.4224\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 109s 14ms/step - loss: 1.2027 - acc: 0.4523 - val_loss: 1.2109 - val_acc: 0.4545\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 103s 14ms/step - loss: 1.1924 - acc: 0.4563 - val_loss: 1.2256 - val_acc: 0.4380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 201/230 [3:23:00<1:44:52, 216.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 94s 11ms/step - loss: 1.2557 - acc: 0.4273 - val_loss: 1.2439 - val_acc: 0.4358\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 93s 12ms/step - loss: 1.2030 - acc: 0.4540 - val_loss: 1.1984 - val_acc: 0.4536\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 97s 13ms/step - loss: 1.1881 - acc: 0.4618 - val_loss: 1.1917 - val_acc: 0.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 202/230 [3:27:45<1:50:48, 237.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 62s 11ms/step - loss: 1.2240 - acc: 0.4442 - val_loss: 1.2047 - val_acc: 0.4453\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 56s 11ms/step - loss: 1.1913 - acc: 0.4617 - val_loss: 1.2024 - val_acc: 0.4514\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 55s 11ms/step - loss: 1.1855 - acc: 0.4646 - val_loss: 1.1823 - val_acc: 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 203/230 [3:30:40<1:38:21, 218.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 58s 11ms/step - loss: 1.2665 - acc: 0.4249 - val_loss: 1.2480 - val_acc: 0.4348\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 53s 10ms/step - loss: 1.2159 - acc: 0.4558 - val_loss: 1.2114 - val_acc: 0.4453\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 55s 11ms/step - loss: 1.1974 - acc: 0.4605 - val_loss: 1.1970 - val_acc: 0.4554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▊ | 204/230 [3:33:28<1:28:06, 203.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 60s 11ms/step - loss: 1.3180 - acc: 0.3946 - val_loss: 1.3142 - val_acc: 0.3989\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 55s 11ms/step - loss: 1.2888 - acc: 0.4062 - val_loss: 1.2637 - val_acc: 0.4170\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 57s 11ms/step - loss: 1.2387 - acc: 0.4424 - val_loss: 1.2324 - val_acc: 0.4390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 205/230 [3:36:21<1:20:59, 194.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 101s 12ms/step - loss: 1.2222 - acc: 0.4466 - val_loss: 1.1897 - val_acc: 0.4525\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 85s 11ms/step - loss: 1.1880 - acc: 0.4607 - val_loss: 1.1820 - val_acc: 0.4632\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 82s 11ms/step - loss: 1.1812 - acc: 0.4663 - val_loss: 1.1860 - val_acc: 0.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|████████▉ | 206/230 [3:40:50<1:26:44, 216.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 109s 13ms/step - loss: 1.2629 - acc: 0.4308 - val_loss: 1.2328 - val_acc: 0.4452\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 93s 12ms/step - loss: 1.2074 - acc: 0.4585 - val_loss: 1.2034 - val_acc: 0.4536\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 94s 12ms/step - loss: 1.1895 - acc: 0.4644 - val_loss: 1.1921 - val_acc: 0.4594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 207/230 [3:45:47<1:32:21, 240.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 79s 10ms/step - loss: 1.3346 - acc: 0.3774 - val_loss: 1.3076 - val_acc: 0.3989\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 73s 10ms/step - loss: 1.2743 - acc: 0.4221 - val_loss: 1.2559 - val_acc: 0.4361\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 75s 10ms/step - loss: 1.2342 - acc: 0.4487 - val_loss: 1.2313 - val_acc: 0.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 208/230 [3:49:36<1:26:58, 237.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 62s 11ms/step - loss: 1.2690 - acc: 0.4255 - val_loss: 1.2359 - val_acc: 0.4436\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 58s 11ms/step - loss: 1.2169 - acc: 0.4569 - val_loss: 1.2135 - val_acc: 0.4496\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 55s 11ms/step - loss: 1.1999 - acc: 0.4599 - val_loss: 1.2002 - val_acc: 0.4513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████ | 209/230 [3:52:31<1:16:32, 218.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 41s 10ms/step - loss: 1.2308 - acc: 0.4427 - val_loss: 1.2247 - val_acc: 0.4310\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 37s 10ms/step - loss: 1.1933 - acc: 0.4589 - val_loss: 1.1927 - val_acc: 0.4562\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 44s 11ms/step - loss: 1.1807 - acc: 0.4665 - val_loss: 1.1906 - val_acc: 0.4569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████▏| 210/230 [3:54:34<1:03:17, 189.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 45s 11ms/step - loss: 1.2382 - acc: 0.4364 - val_loss: 1.2231 - val_acc: 0.4346\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 39s 10ms/step - loss: 1.1942 - acc: 0.4636 - val_loss: 1.1892 - val_acc: 0.4546\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 44s 11ms/step - loss: 1.1809 - acc: 0.4685 - val_loss: 1.1913 - val_acc: 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 211/230 [3:56:44<54:24, 171.79s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 53s 13ms/step - loss: 1.2471 - acc: 0.4317 - val_loss: 1.2174 - val_acc: 0.4326\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 45s 12ms/step - loss: 1.2007 - acc: 0.4534 - val_loss: 1.2133 - val_acc: 0.4305\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 45s 12ms/step - loss: 1.1875 - acc: 0.4620 - val_loss: 1.2267 - val_acc: 0.4502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 212/230 [3:59:08<49:05, 163.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 65s 12ms/step - loss: 1.2431 - acc: 0.4336 - val_loss: 1.2262 - val_acc: 0.4499\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 54s 11ms/step - loss: 1.1987 - acc: 0.4597 - val_loss: 1.2232 - val_acc: 0.4452\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 57s 11ms/step - loss: 1.1868 - acc: 0.4632 - val_loss: 1.1906 - val_acc: 0.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 213/230 [4:02:06<47:33, 167.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 85s 11ms/step - loss: 1.2470 - acc: 0.4319 - val_loss: 1.2219 - val_acc: 0.4452\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 80s 11ms/step - loss: 1.2051 - acc: 0.4571 - val_loss: 1.2010 - val_acc: 0.4546\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 81s 11ms/step - loss: 1.1879 - acc: 0.4635 - val_loss: 1.1993 - val_acc: 0.4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 214/230 [4:06:13<51:05, 191.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 92s 10ms/step - loss: 1.2201 - acc: 0.4483 - val_loss: 1.2516 - val_acc: 0.4432\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 78s 10ms/step - loss: 1.1899 - acc: 0.4636 - val_loss: 1.1822 - val_acc: 0.4629\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 79s 10ms/step - loss: 1.1832 - acc: 0.4671 - val_loss: 1.1813 - val_acc: 0.4644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 215/230 [4:10:23<52:16, 209.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 69s 13ms/step - loss: 1.2962 - acc: 0.4034 - val_loss: 1.2885 - val_acc: 0.3989\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 53s 10ms/step - loss: 1.2624 - acc: 0.4165 - val_loss: 1.2540 - val_acc: 0.4265\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 53s 10ms/step - loss: 1.2368 - acc: 0.4428 - val_loss: 1.2372 - val_acc: 0.4357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 216/230 [4:13:18<46:26, 199.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 16s 3ms/step - loss: 1.4336 - acc: 0.3500 - val_loss: 1.3112 - val_acc: 0.3999\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2978 - acc: 0.4045 - val_loss: 1.3021 - val_acc: 0.3999\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 10s 3ms/step - loss: 1.2864 - acc: 0.4064 - val_loss: 1.2876 - val_acc: 0.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 217/230 [4:13:56<32:37, 150.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 20s 4ms/step - loss: 1.2239 - acc: 0.4470 - val_loss: 1.2582 - val_acc: 0.4424\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.1970 - acc: 0.4653 - val_loss: 1.2100 - val_acc: 0.4481\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.1883 - acc: 0.4654 - val_loss: 1.1958 - val_acc: 0.4563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▍| 218/230 [4:14:52<24:26, 122.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2401 - acc: 0.4374 - val_loss: 1.2171 - val_acc: 0.4432\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1963 - acc: 0.4595 - val_loss: 1.1939 - val_acc: 0.4563\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1821 - acc: 0.4677 - val_loss: 1.1871 - val_acc: 0.4549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 219/230 [4:15:38<18:11, 99.26s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 30s 4ms/step - loss: 1.2963 - acc: 0.4049 - val_loss: 1.2783 - val_acc: 0.3992\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 30s 4ms/step - loss: 1.2363 - acc: 0.4443 - val_loss: 1.2273 - val_acc: 0.4445\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 29s 4ms/step - loss: 1.2158 - acc: 0.4525 - val_loss: 1.2155 - val_acc: 0.4487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 220/230 [4:17:08<16:05, 96.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 14s 3ms/step - loss: 1.2305 - acc: 0.4406 - val_loss: 1.1997 - val_acc: 0.4536\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1899 - acc: 0.4628 - val_loss: 1.1893 - val_acc: 0.4591\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1828 - acc: 0.4662 - val_loss: 1.1834 - val_acc: 0.4635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 221/230 [4:17:45<11:47, 78.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.2250 - acc: 0.4476 - val_loss: 1.2093 - val_acc: 0.4429\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.1918 - acc: 0.4631 - val_loss: 1.2052 - val_acc: 0.4584\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.1846 - acc: 0.4678 - val_loss: 1.1832 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 222/230 [4:18:52<10:01, 75.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 15s 3ms/step - loss: 1.2722 - acc: 0.4195 - val_loss: 1.2342 - val_acc: 0.4387\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.2128 - acc: 0.4550 - val_loss: 1.2083 - val_acc: 0.4484\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.1972 - acc: 0.4600 - val_loss: 1.1968 - val_acc: 0.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 223/230 [4:19:30<07:28, 64.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 14s 3ms/step - loss: 1.2174 - acc: 0.4485 - val_loss: 1.2093 - val_acc: 0.4534\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1954 - acc: 0.4620 - val_loss: 1.1866 - val_acc: 0.4601\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1877 - acc: 0.4644 - val_loss: 1.1869 - val_acc: 0.4646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 224/230 [4:20:08<05:36, 56.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.2510 - acc: 0.4316 - val_loss: 1.2160 - val_acc: 0.4449\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 14s 3ms/step - loss: 1.1993 - acc: 0.4589 - val_loss: 1.1947 - val_acc: 0.4548\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1849 - acc: 0.4633 - val_loss: 1.1902 - val_acc: 0.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 225/230 [4:20:54<04:26, 53.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 18s 3ms/step - loss: 1.2573 - acc: 0.4324 - val_loss: 1.2288 - val_acc: 0.4432\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 17s 3ms/step - loss: 1.2107 - acc: 0.4565 - val_loss: 1.2079 - val_acc: 0.4490\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1945 - acc: 0.4608 - val_loss: 1.1943 - val_acc: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 226/230 [4:21:45<03:29, 52.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 19s 3ms/step - loss: 1.2256 - acc: 0.4410 - val_loss: 1.2002 - val_acc: 0.4505\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1906 - acc: 0.4622 - val_loss: 1.1871 - val_acc: 0.4566\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.1774 - acc: 0.4707 - val_loss: 1.1856 - val_acc: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%|█████████▊| 227/230 [4:22:36<02:36, 52.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5091/5091 [==============================] - 16s 3ms/step - loss: 1.2693 - acc: 0.4241 - val_loss: 1.2268 - val_acc: 0.4395\n",
      "Epoch 2/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.2093 - acc: 0.4583 - val_loss: 1.2081 - val_acc: 0.4517\n",
      "Epoch 3/3\n",
      "5091/5091 [==============================] - 15s 3ms/step - loss: 1.1954 - acc: 0.4627 - val_loss: 1.1965 - val_acc: 0.4591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%|█████████▉| 228/230 [4:23:22<01:40, 50.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3818/3818 [==============================] - 14s 3ms/step - loss: 1.2525 - acc: 0.4341 - val_loss: 1.2206 - val_acc: 0.4435\n",
      "Epoch 2/3\n",
      "3818/3818 [==============================] - 11s 3ms/step - loss: 1.2048 - acc: 0.4554 - val_loss: 1.2376 - val_acc: 0.4377\n",
      "Epoch 3/3\n",
      "3818/3818 [==============================] - 12s 3ms/step - loss: 1.1923 - acc: 0.4604 - val_loss: 1.1898 - val_acc: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████▉| 229/230 [4:23:59<00:46, 46.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.2407 - acc: 0.4411 - val_loss: 1.2214 - val_acc: 0.4444\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.2013 - acc: 0.4589 - val_loss: 1.2065 - val_acc: 0.4514\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.1881 - acc: 0.4628 - val_loss: 1.1879 - val_acc: 0.4577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 230/230 [4:25:09<00:00, 69.17s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "scan_object = talos.Scan(x,\n",
    "                         y, \n",
    "                         params=p,\n",
    "                         model=OSA_model,\n",
    "                         experiment_name='OSA_hyper_rnn',\n",
    "                         fraction_limit=.001)\n",
    "# By defaul, this function uses 70:30 split for training/ validation\n",
    "#To get started quickly, we're going to invoke the 'grid_downsample' parameter to 1/100 of the entire permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18dfc09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>lr</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>loss</th>\n",
       "      <th>first_activation</th>\n",
       "      <th>second_activation</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>weight_regulizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07/12/22-135159</td>\n",
       "      <td>07/12/22-135417</td>\n",
       "      <td>137.980660</td>\n",
       "      <td>3</td>\n",
       "      <td>1.197676</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>1.207125</td>\n",
       "      <td>0.450199</td>\n",
       "      <td>0.37</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/12/22-135418</td>\n",
       "      <td>07/12/22-135609</td>\n",
       "      <td>110.600623</td>\n",
       "      <td>3</td>\n",
       "      <td>1.188195</td>\n",
       "      <td>0.461564</td>\n",
       "      <td>1.205299</td>\n",
       "      <td>0.444088</td>\n",
       "      <td>0.64</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softsign</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07/12/22-135610</td>\n",
       "      <td>07/12/22-135800</td>\n",
       "      <td>110.705322</td>\n",
       "      <td>3</td>\n",
       "      <td>1.202167</td>\n",
       "      <td>0.455932</td>\n",
       "      <td>1.202921</td>\n",
       "      <td>0.453712</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/12/22-135801</td>\n",
       "      <td>07/12/22-135947</td>\n",
       "      <td>105.722821</td>\n",
       "      <td>3</td>\n",
       "      <td>1.199368</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>1.204411</td>\n",
       "      <td>0.451879</td>\n",
       "      <td>0.46</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07/12/22-135948</td>\n",
       "      <td>07/12/22-140143</td>\n",
       "      <td>115.413643</td>\n",
       "      <td>3</td>\n",
       "      <td>1.181062</td>\n",
       "      <td>0.465492</td>\n",
       "      <td>1.190583</td>\n",
       "      <td>0.456462</td>\n",
       "      <td>0.28</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             start              end    duration  round_epochs      loss  \\\n",
       "0  07/12/22-135159  07/12/22-135417  137.980660             3  1.197676   \n",
       "1  07/12/22-135418  07/12/22-135609  110.600623             3  1.188195   \n",
       "2  07/12/22-135610  07/12/22-135800  110.705322             3  1.202167   \n",
       "3  07/12/22-135801  07/12/22-135947  105.722821             3  1.199368   \n",
       "4  07/12/22-135948  07/12/22-140143  115.413643             3  1.181062   \n",
       "\n",
       "        acc  val_loss   val_acc    lr  first_neuron  batch_size  epochs  \\\n",
       "0  0.461891  1.207125  0.450199  0.37             8           4       3   \n",
       "1  0.461564  1.205299  0.444088  0.64           128           4       3   \n",
       "2  0.455932  1.202921  0.453712  0.37             4           4       3   \n",
       "3  0.461891  1.204411  0.451879  0.46            32           4       3   \n",
       "4  0.465492  1.190583  0.456462  0.28            32           4       3   \n",
       "\n",
       "   dropout                                          optimizer  \\\n",
       "0     0.36  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "1     0.20  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "2     0.24  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "3     0.04  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "4     0.20  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "\n",
       "                       loss first_activation second_activation  \\\n",
       "0  categorical_crossentropy         softplus           softmax   \n",
       "1  categorical_crossentropy         softsign           sigmoid   \n",
       "2  categorical_crossentropy          sigmoid              tanh   \n",
       "3  categorical_crossentropy           linear           softmax   \n",
       "4  categorical_crossentropy             relu           sigmoid   \n",
       "\n",
       "  last_activation weight_regulizer  \n",
       "0         softmax             None  \n",
       "1         softmax             None  \n",
       "2         softmax             None  \n",
       "3         softmax             None  \n",
       "4         softmax             None  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_object.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe383f4",
   "metadata": {},
   "source": [
    "### Analysing the Scan results with Reporting() \n",
    "\n",
    "In the Scan process, the results are stored round-by-round in the \n",
    "corresponding experiment log which is a .csv file stored in the present working directory. \n",
    "The Reporting() accepts as its source either a file name, or the Scan object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6e24629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Scan object as input\n",
    "analyze_object = talos.Analyze(scan_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bcf1195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>lr</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>loss</th>\n",
       "      <th>first_activation</th>\n",
       "      <th>second_activation</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>weight_regulizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07/12/22-135159</td>\n",
       "      <td>07/12/22-135417</td>\n",
       "      <td>137.980660</td>\n",
       "      <td>3</td>\n",
       "      <td>1.197676</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>1.207125</td>\n",
       "      <td>0.450199</td>\n",
       "      <td>0.37</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/12/22-135418</td>\n",
       "      <td>07/12/22-135609</td>\n",
       "      <td>110.600623</td>\n",
       "      <td>3</td>\n",
       "      <td>1.188195</td>\n",
       "      <td>0.461564</td>\n",
       "      <td>1.205299</td>\n",
       "      <td>0.444088</td>\n",
       "      <td>0.64</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softsign</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07/12/22-135610</td>\n",
       "      <td>07/12/22-135800</td>\n",
       "      <td>110.705322</td>\n",
       "      <td>3</td>\n",
       "      <td>1.202167</td>\n",
       "      <td>0.455932</td>\n",
       "      <td>1.202921</td>\n",
       "      <td>0.453712</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/12/22-135801</td>\n",
       "      <td>07/12/22-135947</td>\n",
       "      <td>105.722821</td>\n",
       "      <td>3</td>\n",
       "      <td>1.199368</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>1.204411</td>\n",
       "      <td>0.451879</td>\n",
       "      <td>0.46</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07/12/22-135948</td>\n",
       "      <td>07/12/22-140143</td>\n",
       "      <td>115.413643</td>\n",
       "      <td>3</td>\n",
       "      <td>1.181062</td>\n",
       "      <td>0.465492</td>\n",
       "      <td>1.190583</td>\n",
       "      <td>0.456462</td>\n",
       "      <td>0.28</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>07/12/22-181254</td>\n",
       "      <td>07/12/22-181344</td>\n",
       "      <td>50.062912</td>\n",
       "      <td>3</td>\n",
       "      <td>1.194547</td>\n",
       "      <td>0.460843</td>\n",
       "      <td>1.194282</td>\n",
       "      <td>0.455851</td>\n",
       "      <td>0.37</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softsign</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>07/12/22-181345</td>\n",
       "      <td>07/12/22-181436</td>\n",
       "      <td>51.024139</td>\n",
       "      <td>3</td>\n",
       "      <td>1.177363</td>\n",
       "      <td>0.470665</td>\n",
       "      <td>1.185577</td>\n",
       "      <td>0.459212</td>\n",
       "      <td>0.19</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>07/12/22-181436</td>\n",
       "      <td>07/12/22-181521</td>\n",
       "      <td>45.443515</td>\n",
       "      <td>3</td>\n",
       "      <td>1.195440</td>\n",
       "      <td>0.462677</td>\n",
       "      <td>1.196462</td>\n",
       "      <td>0.459059</td>\n",
       "      <td>0.37</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>07/12/22-181522</td>\n",
       "      <td>07/12/22-181558</td>\n",
       "      <td>36.424705</td>\n",
       "      <td>3</td>\n",
       "      <td>1.192337</td>\n",
       "      <td>0.460385</td>\n",
       "      <td>1.189840</td>\n",
       "      <td>0.455851</td>\n",
       "      <td>0.37</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>07/12/22-181559</td>\n",
       "      <td>07/12/22-181708</td>\n",
       "      <td>69.621807</td>\n",
       "      <td>3</td>\n",
       "      <td>1.188099</td>\n",
       "      <td>0.462808</td>\n",
       "      <td>1.187941</td>\n",
       "      <td>0.457684</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               start              end    duration  round_epochs      loss  \\\n",
       "0    07/12/22-135159  07/12/22-135417  137.980660             3  1.197676   \n",
       "1    07/12/22-135418  07/12/22-135609  110.600623             3  1.188195   \n",
       "2    07/12/22-135610  07/12/22-135800  110.705322             3  1.202167   \n",
       "3    07/12/22-135801  07/12/22-135947  105.722821             3  1.199368   \n",
       "4    07/12/22-135948  07/12/22-140143  115.413643             3  1.181062   \n",
       "..               ...              ...         ...           ...       ...   \n",
       "225  07/12/22-181254  07/12/22-181344   50.062912             3  1.194547   \n",
       "226  07/12/22-181345  07/12/22-181436   51.024139             3  1.177363   \n",
       "227  07/12/22-181436  07/12/22-181521   45.443515             3  1.195440   \n",
       "228  07/12/22-181522  07/12/22-181558   36.424705             3  1.192337   \n",
       "229  07/12/22-181559  07/12/22-181708   69.621807             3  1.188099   \n",
       "\n",
       "          acc  val_loss   val_acc    lr  first_neuron  batch_size  epochs  \\\n",
       "0    0.461891  1.207125  0.450199  0.37             8           4       3   \n",
       "1    0.461564  1.205299  0.444088  0.64           128           4       3   \n",
       "2    0.455932  1.202921  0.453712  0.37             4           4       3   \n",
       "3    0.461891  1.204411  0.451879  0.46            32           4       3   \n",
       "4    0.465492  1.190583  0.456462  0.28            32           4       3   \n",
       "..        ...       ...       ...   ...           ...         ...     ...   \n",
       "225  0.460843  1.194282  0.455851  0.37            16           3       3   \n",
       "226  0.470665  1.185577  0.459212  0.19            64           3       3   \n",
       "227  0.462677  1.196462  0.459059  0.37            16           3       3   \n",
       "228  0.460385  1.189840  0.455851  0.37            64           4       3   \n",
       "229  0.462808  1.187941  0.457684  0.46             8           2       3   \n",
       "\n",
       "     dropout                                          optimizer  \\\n",
       "0       0.36  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "1       0.20  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "2       0.24  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "3       0.04  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "4       0.20  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "..       ...                                                ...   \n",
       "225     0.00  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "226     0.24  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "227     0.04  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "228     0.20  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "229     0.12  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "\n",
       "                         loss first_activation second_activation  \\\n",
       "0    categorical_crossentropy         softplus           softmax   \n",
       "1    categorical_crossentropy         softsign           sigmoid   \n",
       "2    categorical_crossentropy          sigmoid              tanh   \n",
       "3    categorical_crossentropy           linear           softmax   \n",
       "4    categorical_crossentropy             relu           sigmoid   \n",
       "..                        ...              ...               ...   \n",
       "225  categorical_crossentropy         softsign           softmax   \n",
       "226  categorical_crossentropy             relu            linear   \n",
       "227  categorical_crossentropy           linear           sigmoid   \n",
       "228  categorical_crossentropy     hard_sigmoid              relu   \n",
       "229  categorical_crossentropy          sigmoid              relu   \n",
       "\n",
       "    last_activation weight_regulizer  \n",
       "0           softmax             None  \n",
       "1           softmax             None  \n",
       "2           softmax             None  \n",
       "3           softmax             None  \n",
       "4           softmax             None  \n",
       "..              ...              ...  \n",
       "225         softmax             None  \n",
       "226         softmax             None  \n",
       "227         softmax             None  \n",
       "228         softmax             None  \n",
       "229         softmax             None  \n",
       "\n",
       "[230 rows x 19 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access the dataframe with the results\n",
    "analyze_object.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "697ae016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4680721163749695"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the highest result for any metric\n",
    "analyze_object.high('val_acc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "69f7c67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_object.rounds2high('val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3ba7ff90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start                                                  07/12/22-150534\n",
       "end                                                    07/12/22-150633\n",
       "duration                                                     59.312222\n",
       "round_epochs                                                         3\n",
       "loss                                                          1.182898\n",
       "acc                                                           0.468504\n",
       "val_loss                                                      1.184535\n",
       "val_acc                                                       0.468072\n",
       "lr                                                                0.55\n",
       "first_neuron                                                         4\n",
       "batch_size                                                           2\n",
       "epochs                                                               3\n",
       "dropout                                                           0.12\n",
       "optimizer            <class 'keras.optimizers.optimizer_v2.nadam.Na...\n",
       "loss                                          categorical_crossentropy\n",
       "first_activation                                              softplus\n",
       "second_activation                                                 tanh\n",
       "last_activation                                                softmax\n",
       "weight_regulizer                                                  None\n",
       "Name: 63, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = analyze_object.rounds2high('val_acc')\n",
    "analyze_object.data.loc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "513fa539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['tanh', 3, '07/12/22-150534', 4,\n",
       "        <class 'keras.optimizers.optimizer_v2.nadam.Nadam'>, 'softmax',\n",
       "        '07/12/22-150633', 0.12, 3, 59.312222480773926, 'softplus', 2,\n",
       "        None, 0.5499999999999999, 0]], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best paramaters\n",
    "analyze_object.best_params('val_acc', ['acc', 'loss', 'val_loss'], n = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff446465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration        0.015553\n",
       "round_epochs         NaN\n",
       "val_acc        -0.934248\n",
       "lr             -0.492566\n",
       "first_neuron   -0.227415\n",
       "batch_size      0.043487\n",
       "epochs               NaN\n",
       "dropout         0.096593\n",
       "Name: val_loss, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correlation for hyperparameters against a metric\n",
    "analyze_object.correlate('val_loss', ['acc', 'loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c65aba8",
   "metadata": {},
   "source": [
    "### Increasing the number of hidden layers for SimpleRNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c4640",
   "metadata": {},
   "source": [
    "#### RNN2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb0a63fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 5s 3ms/step - loss: 1.2589 - accuracy: 0.4288\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 1.2058 - accuracy: 0.4530\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 4s 8ms/step - loss: 1.1896 - accuracy: 0.4605\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 1.1830 - accuracy: 0.4673\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 4s 8ms/step - loss: 1.1767 - accuracy: 0.4678\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 4s 8ms/step - loss: 1.1716 - accuracy: 0.4743\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 4s 8ms/step - loss: 1.1691 - accuracy: 0.4735\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 4s 8ms/step - loss: 1.1689 - accuracy: 0.4750\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 5s 9ms/step - loss: 1.1652 - accuracy: 0.4763\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 4s 8ms/step - loss: 1.1637 - accuracy: 0.4794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9352917f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN2 = Sequential()                            \n",
    "model_RNN2.add(SimpleRNN(16,\n",
    "                    activation='tanh'))\n",
    "    \n",
    "model_RNN2.add(Dense(16,\n",
    "                    input_dim=X_train_lstm.shape[1],\n",
    "                    activation='relu'))\n",
    "model_RNN2.add(Dense(16,\n",
    "                    activation='relu'))\n",
    "    \n",
    "model_RNN2.add(Dense(4,\n",
    "                    activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001, decay = 1e-5)  # the optimizer settings can have a large impact. Decay, decreases the learning rate\n",
    "model_RNN2.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model_RNN2.fit(X_train_lstm, y_train, epochs = 10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83763307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 2s 6ms/step - loss: 1.1785 - accuracy: 0.4711\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model_RNN2.evaluate(X_test_lstm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fada32ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.24      0.33       572\n",
      "           1       0.34      0.40      0.37      1007\n",
      "           2       0.33      0.10      0.16      1029\n",
      "           3       0.54      0.80      0.65      1756\n",
      "\n",
      "    accuracy                           0.47      4364\n",
      "   macro avg       0.43      0.39      0.38      4364\n",
      "weighted avg       0.44      0.47      0.43      4364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_RNN2.predict(X_test_lstm)\n",
    "y_pred_sev = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e36b8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred_sev)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['0', '1','2', '3']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('SimpleRNN2 Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac68aa",
   "metadata": {},
   "source": [
    "### RNN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d92e11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 4s 4ms/step - loss: 1.2933 - accuracy: 0.3871\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 1s 3ms/step - loss: 1.2406 - accuracy: 0.4346\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 1.2198 - accuracy: 0.4491\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 1.2087 - accuracy: 0.4538\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 1.2012 - accuracy: 0.4567\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 1.1946 - accuracy: 0.4583\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 4s 8ms/step - loss: 1.1898 - accuracy: 0.4640\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 1.1852 - accuracy: 0.4645\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 1.1816 - accuracy: 0.4673\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 4s 7ms/step - loss: 1.1788 - accuracy: 0.4692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a93bc34340>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN3 = Sequential()                            \n",
    "model_RNN3.add(SimpleRNN(16,\n",
    "                    activation='linear'))\n",
    "    \n",
    "model_RNN3.add(Dense(16,\n",
    "                    input_dim=X_train_lstm.shape[1],\n",
    "                    activation='relu'))\n",
    "model_RNN3.add(Dense(16,\n",
    "                    activation='relu'))\n",
    "    \n",
    "model_RNN3.add(Dense(4,\n",
    "                    activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adamax(learning_rate = 0.001, decay = 1e-5)  # the optimizer settings can have a large impact. Decay, decreases the learning rate\n",
    "model_RNN3.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model_RNN3.fit(X_train_lstm, y_train, epochs = 10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9b1e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 1s 2ms/step - loss: 1.1868 - accuracy: 0.4539\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model_RNN3.evaluate(X_test_lstm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1844217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.16      0.24       572\n",
      "           1       0.32      0.34      0.33      1007\n",
      "           2       0.26      0.05      0.08      1029\n",
      "           3       0.51      0.86      0.64      1756\n",
      "\n",
      "    accuracy                           0.45      4364\n",
      "   macro avg       0.40      0.35      0.32      4364\n",
      "weighted avg       0.41      0.45      0.38      4364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_RNN3.predict(X_test_lstm)\n",
    "y_pred_sev = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0189acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dc71f00",
   "metadata": {},
   "source": [
    "## LSTM Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2b4e0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSA_model(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    model = Sequential()                            \n",
    "    model.add(LSTM(params['first_neuron'],\n",
    "                    activation=params['first_activation']))\n",
    "    \n",
    "    model.add(Dense(params['first_neuron'],\n",
    "                    input_dim=x_train.shape[1],\n",
    "                    activation=params['second_activation']))\n",
    "    \n",
    "    model.add(Dense(y_train.shape[1],\n",
    "                    activation=params['last_activation']))\n",
    "\n",
    "    model.compile(optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], params['optimizer'])),\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=1,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "508a1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'lr': (0.001, 0.01, 0.1),\n",
    "     'first_neuron':[4, 8, 16, 32, 64, 128],\n",
    "     'batch_size': [5, 10, 20],\n",
    "     'epochs': [5],\n",
    "     'optimizer': [Adam, Nadam, Adamax],\n",
    "     'loss': ['categorical_crossentropy'],\n",
    "     'first_activation': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "     'second_activation': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "     'last_activation': ['softmax']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "460f9071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3055/3055 [==============================] - 72s 18ms/step - loss: 1.5012 - acc: 0.2336 - val_loss: 1.4739 - val_acc: 0.2406\n",
      "Epoch 2/3\n",
      "3055/3055 [==============================] - 50s 16ms/step - loss: 1.4555 - acc: 0.2336 - val_loss: 1.4335 - val_acc: 0.2406\n",
      "Epoch 3/3\n",
      "3055/3055 [==============================] - 48s 16ms/step - loss: 1.4184 - acc: 0.2336 - val_loss: 1.4008 - val_acc: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/46 [02:52<2:09:22, 172.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 63s 16ms/step - loss: 2.3697 - acc: 0.2298 - val_loss: 2.3254 - val_acc: 0.2333\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 40s 13ms/step - loss: 2.3344 - acc: 0.2298 - val_loss: 2.2908 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 40s 13ms/step - loss: 2.2998 - acc: 0.2298 - val_loss: 2.2572 - val_acc: 0.2333\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 40s 13ms/step - loss: 2.2660 - acc: 0.2298 - val_loss: 2.2242 - val_acc: 0.2333\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 43s 14ms/step - loss: 2.2327 - acc: 0.2298 - val_loss: 2.1919 - val_acc: 0.2333\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 37s 12ms/step - loss: 2.2001 - acc: 0.2298 - val_loss: 2.1600 - val_acc: 0.2333\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 36s 12ms/step - loss: 2.1681 - acc: 0.2298 - val_loss: 2.1290 - val_acc: 0.2333\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 34s 11ms/step - loss: 2.1368 - acc: 0.2298 - val_loss: 2.0986 - val_acc: 0.2333\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 34s 11ms/step - loss: 2.1062 - acc: 0.2298 - val_loss: 2.0688 - val_acc: 0.2333\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 35s 12ms/step - loss: 2.0763 - acc: 0.2298 - val_loss: 2.0397 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 2/46 [09:36<3:46:17, 308.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3055/3055 [==============================] - 49s 13ms/step - loss: 1.3824 - acc: 0.2950 - val_loss: 1.3817 - val_acc: 0.3074\n",
      "Epoch 2/3\n",
      "3055/3055 [==============================] - 38s 12ms/step - loss: 1.3802 - acc: 0.3166 - val_loss: 1.3796 - val_acc: 0.3239\n",
      "Epoch 3/3\n",
      "3055/3055 [==============================] - 38s 12ms/step - loss: 1.3780 - acc: 0.3334 - val_loss: 1.3775 - val_acc: 0.3394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 3/46 [11:42<2:41:31, 225.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 49s 13ms/step - loss: 1.4365 - acc: 0.2298 - val_loss: 1.4313 - val_acc: 0.2333\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 38s 13ms/step - loss: 1.4245 - acc: 0.2298 - val_loss: 1.4200 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 37s 12ms/step - loss: 1.4135 - acc: 0.2298 - val_loss: 1.4096 - val_acc: 0.2333\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 47s 15ms/step - loss: 1.4033 - acc: 0.2298 - val_loss: 1.4001 - val_acc: 0.2333\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 41s 13ms/step - loss: 1.3940 - acc: 0.2298 - val_loss: 1.3913 - val_acc: 0.2331\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 39s 13ms/step - loss: 1.3856 - acc: 0.2311 - val_loss: 1.3834 - val_acc: 0.2342\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 40s 13ms/step - loss: 1.3779 - acc: 0.2371 - val_loss: 1.3762 - val_acc: 0.2450\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 40s 13ms/step - loss: 1.3708 - acc: 0.2607 - val_loss: 1.3696 - val_acc: 0.2797\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 41s 13ms/step - loss: 1.3644 - acc: 0.3159 - val_loss: 1.3636 - val_acc: 0.3320\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 45s 15ms/step - loss: 1.3586 - acc: 0.3703 - val_loss: 1.3583 - val_acc: 0.3802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▊         | 4/46 [18:41<3:31:19, 301.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 35s 9ms/step - loss: 1.4123 - acc: 0.2336 - val_loss: 1.4081 - val_acc: 0.2406\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 43s 14ms/step - loss: 1.4084 - acc: 0.2336 - val_loss: 1.4043 - val_acc: 0.2406\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 41s 13ms/step - loss: 1.4046 - acc: 0.2336 - val_loss: 1.4007 - val_acc: 0.2406\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 36s 12ms/step - loss: 1.4009 - acc: 0.2336 - val_loss: 1.3971 - val_acc: 0.2406\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 36s 12ms/step - loss: 1.3973 - acc: 0.2336 - val_loss: 1.3936 - val_acc: 0.2406\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 36s 12ms/step - loss: 1.3938 - acc: 0.2336 - val_loss: 1.3903 - val_acc: 0.2406\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 41s 13ms/step - loss: 1.3904 - acc: 0.2336 - val_loss: 1.3870 - val_acc: 0.2406\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 42s 14ms/step - loss: 1.3871 - acc: 0.2336 - val_loss: 1.3838 - val_acc: 0.2406\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 59s 19ms/step - loss: 1.3838 - acc: 0.2336 - val_loss: 1.3806 - val_acc: 0.2409\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 51s 17ms/step - loss: 1.3807 - acc: 0.2334 - val_loss: 1.3776 - val_acc: 0.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 5/46 [25:42<3:55:31, 344.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1528/1528 [==============================] - 38s 15ms/step - loss: 1.3820 - acc: 0.2727 - val_loss: 1.3779 - val_acc: 0.2903\n",
      "Epoch 2/10\n",
      "1528/1528 [==============================] - 22s 15ms/step - loss: 1.3745 - acc: 0.3096 - val_loss: 1.3707 - val_acc: 0.3207\n",
      "Epoch 3/10\n",
      "1528/1528 [==============================] - 17s 11ms/step - loss: 1.3676 - acc: 0.3373 - val_loss: 1.3640 - val_acc: 0.3478\n",
      "Epoch 4/10\n",
      "1528/1528 [==============================] - 19s 12ms/step - loss: 1.3611 - acc: 0.3601 - val_loss: 1.3578 - val_acc: 0.3613\n",
      "Epoch 5/10\n",
      "1528/1528 [==============================] - 19s 13ms/step - loss: 1.3550 - acc: 0.3770 - val_loss: 1.3518 - val_acc: 0.3732\n",
      "Epoch 6/10\n",
      "1528/1528 [==============================] - 16s 10ms/step - loss: 1.3492 - acc: 0.3861 - val_loss: 1.3463 - val_acc: 0.3837\n",
      "Epoch 7/10\n",
      "1528/1528 [==============================] - 16s 10ms/step - loss: 1.3438 - acc: 0.3947 - val_loss: 1.3410 - val_acc: 0.3903\n",
      "Epoch 8/10\n",
      "1528/1528 [==============================] - 16s 10ms/step - loss: 1.3386 - acc: 0.3986 - val_loss: 1.3361 - val_acc: 0.3938\n",
      "Epoch 9/10\n",
      "1528/1528 [==============================] - 16s 11ms/step - loss: 1.3338 - acc: 0.4009 - val_loss: 1.3315 - val_acc: 0.3946\n",
      "Epoch 10/10\n",
      "1528/1528 [==============================] - 17s 11ms/step - loss: 1.3293 - acc: 0.4024 - val_loss: 1.3271 - val_acc: 0.3947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 6/46 [29:01<3:16:41, 295.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 52s 11ms/step - loss: 1.7508 - acc: 0.2298 - val_loss: 1.7278 - val_acc: 0.2333\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.7180 - acc: 0.2298 - val_loss: 1.6965 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.6872 - acc: 0.2298 - val_loss: 1.6672 - val_acc: 0.2333\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.6584 - acc: 0.2298 - val_loss: 1.6398 - val_acc: 0.2333\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.6316 - acc: 0.2298 - val_loss: 1.6144 - val_acc: 0.2333\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.6068 - acc: 0.2298 - val_loss: 1.5909 - val_acc: 0.2333\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.5836 - acc: 0.2298 - val_loss: 1.5689 - val_acc: 0.2333\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.5622 - acc: 0.2298 - val_loss: 1.5487 - val_acc: 0.2333\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.5424 - acc: 0.2298 - val_loss: 1.5299 - val_acc: 0.2333\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.5240 - acc: 0.2298 - val_loss: 1.5125 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 7/46 [31:21<2:38:51, 244.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3922 - acc: 0.1997 - val_loss: 1.3910 - val_acc: 0.2189\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.3890 - acc: 0.2338 - val_loss: 1.3879 - val_acc: 0.2527\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3861 - acc: 0.2686 - val_loss: 1.3851 - val_acc: 0.2866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 8/46 [32:26<1:58:33, 187.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 13s 4ms/step - loss: 1.5309 - acc: 0.2298 - val_loss: 1.5068 - val_acc: 0.2333\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 11s 4ms/step - loss: 1.4980 - acc: 0.2298 - val_loss: 1.4763 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.4680 - acc: 0.2298 - val_loss: 1.4487 - val_acc: 0.2333\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 11s 4ms/step - loss: 1.4412 - acc: 0.2298 - val_loss: 1.4244 - val_acc: 0.2333\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 12s 4ms/step - loss: 1.4177 - acc: 0.2298 - val_loss: 1.4032 - val_acc: 0.2333\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 14s 5ms/step - loss: 1.3973 - acc: 0.2298 - val_loss: 1.3851 - val_acc: 0.2333\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 14s 5ms/step - loss: 1.3800 - acc: 0.2298 - val_loss: 1.3699 - val_acc: 0.2333\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 13s 4ms/step - loss: 1.3655 - acc: 0.2298 - val_loss: 1.3572 - val_acc: 0.2333\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 12s 4ms/step - loss: 1.3534 - acc: 0.2567 - val_loss: 1.3470 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 11s 4ms/step - loss: 1.3437 - acc: 0.4045 - val_loss: 1.3388 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 9/46 [34:27<1:42:43, 166.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 11s 3ms/step - loss: 1.3907 - acc: 0.2308 - val_loss: 1.3896 - val_acc: 0.2319\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3889 - acc: 0.2305 - val_loss: 1.3879 - val_acc: 0.2334\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.3872 - acc: 0.2299 - val_loss: 1.3862 - val_acc: 0.2339\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3855 - acc: 0.2294 - val_loss: 1.3846 - val_acc: 0.2353\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3838 - acc: 0.2360 - val_loss: 1.3829 - val_acc: 0.2449\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3821 - acc: 0.2706 - val_loss: 1.3814 - val_acc: 0.3090\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.3805 - acc: 0.3508 - val_loss: 1.3798 - val_acc: 0.3712\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3789 - acc: 0.3964 - val_loss: 1.3782 - val_acc: 0.3961\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3773 - acc: 0.4043 - val_loss: 1.3767 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3758 - acc: 0.4045 - val_loss: 1.3752 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 10/46 [36:02<1:26:47, 144.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1528/1528 [==============================] - 10s 4ms/step - loss: 1.4194 - acc: 0.1793 - val_loss: 1.4119 - val_acc: 0.1951\n",
      "Epoch 2/3\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.4103 - acc: 0.1939 - val_loss: 1.4034 - val_acc: 0.2169\n",
      "Epoch 3/3\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4018 - acc: 0.2156 - val_loss: 1.3956 - val_acc: 0.2383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 11/46 [36:24<1:02:21, 106.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.3852 - acc: 0.2324 - val_loss: 1.3846 - val_acc: 0.3245\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3820 - acc: 0.3817 - val_loss: 1.3814 - val_acc: 0.3951\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3788 - acc: 0.4034 - val_loss: 1.3783 - val_acc: 0.3978\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3758 - acc: 0.4045 - val_loss: 1.3753 - val_acc: 0.3978\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3729 - acc: 0.4045 - val_loss: 1.3725 - val_acc: 0.3975\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.3700 - acc: 0.4043 - val_loss: 1.3697 - val_acc: 0.3972\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3673 - acc: 0.4045 - val_loss: 1.3670 - val_acc: 0.3972\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3647 - acc: 0.4045 - val_loss: 1.3645 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3621 - acc: 0.4045 - val_loss: 1.3620 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3597 - acc: 0.4045 - val_loss: 1.3596 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 12/46 [40:15<1:21:58, 144.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1528/1528 [==============================] - 7s 3ms/step - loss: 1.4660 - acc: 0.2298 - val_loss: 1.4562 - val_acc: 0.2333\n",
      "Epoch 2/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4539 - acc: 0.2298 - val_loss: 1.4448 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4425 - acc: 0.2298 - val_loss: 1.4340 - val_acc: 0.2333\n",
      "Epoch 4/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4317 - acc: 0.2298 - val_loss: 1.4238 - val_acc: 0.2333\n",
      "Epoch 5/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4215 - acc: 0.2298 - val_loss: 1.4142 - val_acc: 0.2333\n",
      "Epoch 6/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4119 - acc: 0.2298 - val_loss: 1.4052 - val_acc: 0.2333\n",
      "Epoch 7/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4028 - acc: 0.2298 - val_loss: 1.3966 - val_acc: 0.2333\n",
      "Epoch 8/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3943 - acc: 0.2298 - val_loss: 1.3887 - val_acc: 0.2333\n",
      "Epoch 9/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3864 - acc: 0.2298 - val_loss: 1.3814 - val_acc: 0.2333\n",
      "Epoch 10/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.3791 - acc: 0.2298 - val_loss: 1.3746 - val_acc: 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 13/46 [41:04<1:03:41, 115.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1528/1528 [==============================] - 10s 5ms/step - loss: 1.3829 - acc: 0.4045 - val_loss: 1.3613 - val_acc: 0.3972\n",
      "Epoch 2/3\n",
      "1528/1528 [==============================] - 8s 5ms/step - loss: 1.3402 - acc: 0.4045 - val_loss: 1.3324 - val_acc: 0.3972\n",
      "Epoch 3/3\n",
      "1528/1528 [==============================] - 7s 5ms/step - loss: 1.3207 - acc: 0.4045 - val_loss: 1.3189 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 14/46 [41:31<47:24, 88.90s/it]   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 27s 3ms/step - loss: 1.6844 - acc: 0.2336 - val_loss: 1.5837 - val_acc: 0.2406\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.5196 - acc: 0.2336 - val_loss: 1.4516 - val_acc: 0.2406\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.4129 - acc: 0.2336 - val_loss: 1.3743 - val_acc: 0.2417\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3545 - acc: 0.2819 - val_loss: 1.3364 - val_acc: 0.3494\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3274 - acc: 0.3824 - val_loss: 1.3203 - val_acc: 0.3975\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3157 - acc: 0.4031 - val_loss: 1.3136 - val_acc: 0.3987\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.3105 - acc: 0.4054 - val_loss: 1.3106 - val_acc: 0.3976\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3080 - acc: 0.4051 - val_loss: 1.3091 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.3065 - acc: 0.4048 - val_loss: 1.3080 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.3054 - acc: 0.4047 - val_loss: 1.3072 - val_acc: 0.3970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 15/46 [45:30<1:09:22, 134.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1528/1528 [==============================] - 9s 4ms/step - loss: 1.6382 - acc: 0.2336 - val_loss: 1.6241 - val_acc: 0.2406\n",
      "Epoch 2/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.6182 - acc: 0.2336 - val_loss: 1.6047 - val_acc: 0.2406\n",
      "Epoch 3/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.5990 - acc: 0.2336 - val_loss: 1.5861 - val_acc: 0.2406\n",
      "Epoch 4/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.5805 - acc: 0.2336 - val_loss: 1.5682 - val_acc: 0.2406\n",
      "Epoch 5/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.5626 - acc: 0.2336 - val_loss: 1.5509 - val_acc: 0.2406\n",
      "Epoch 6/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.5454 - acc: 0.2336 - val_loss: 1.5342 - val_acc: 0.2406\n",
      "Epoch 7/10\n",
      "1528/1528 [==============================] - 5s 4ms/step - loss: 1.5289 - acc: 0.2336 - val_loss: 1.5184 - val_acc: 0.2406\n",
      "Epoch 8/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.5132 - acc: 0.2336 - val_loss: 1.5032 - val_acc: 0.2406\n",
      "Epoch 9/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4981 - acc: 0.2336 - val_loss: 1.4887 - val_acc: 0.2406\n",
      "Epoch 10/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4837 - acc: 0.2336 - val_loss: 1.4749 - val_acc: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 16/46 [46:25<55:08, 110.29s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 28s 3ms/step - loss: 1.3303 - acc: 0.4045 - val_loss: 1.3184 - val_acc: 0.3972\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 27s 4ms/step - loss: 1.3110 - acc: 0.4045 - val_loss: 1.3118 - val_acc: 0.3972\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 30s 4ms/step - loss: 1.3076 - acc: 0.4045 - val_loss: 1.3093 - val_acc: 0.3972\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 27s 3ms/step - loss: 1.3059 - acc: 0.4045 - val_loss: 1.3077 - val_acc: 0.3972\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.3046 - acc: 0.4045 - val_loss: 1.3064 - val_acc: 0.3972\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 27s 4ms/step - loss: 1.3033 - acc: 0.4045 - val_loss: 1.3052 - val_acc: 0.3972\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 27s 3ms/step - loss: 1.3021 - acc: 0.4045 - val_loss: 1.3039 - val_acc: 0.3972\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.3008 - acc: 0.4045 - val_loss: 1.3027 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 27s 3ms/step - loss: 1.2995 - acc: 0.4045 - val_loss: 1.3014 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.2982 - acc: 0.4045 - val_loss: 1.3000 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 17/46 [50:56<1:16:44, 158.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.3467 - acc: 0.2942 - val_loss: 1.3317 - val_acc: 0.3963\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3220 - acc: 0.4047 - val_loss: 1.3184 - val_acc: 0.3972\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3130 - acc: 0.4045 - val_loss: 1.3132 - val_acc: 0.3972\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3092 - acc: 0.4045 - val_loss: 1.3107 - val_acc: 0.3972\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3072 - acc: 0.4045 - val_loss: 1.3093 - val_acc: 0.3972\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3058 - acc: 0.4045 - val_loss: 1.3081 - val_acc: 0.3972\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3047 - acc: 0.4045 - val_loss: 1.3071 - val_acc: 0.3972\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3037 - acc: 0.4045 - val_loss: 1.3061 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.3026 - acc: 0.4045 - val_loss: 1.3052 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.3016 - acc: 0.4045 - val_loss: 1.3042 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 18/46 [54:46<1:24:06, 180.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1528/1528 [==============================] - 10s 4ms/step - loss: 1.4131 - acc: 0.2308 - val_loss: 1.4057 - val_acc: 0.2368\n",
      "Epoch 2/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4017 - acc: 0.2343 - val_loss: 1.3953 - val_acc: 0.2400\n",
      "Epoch 3/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.3915 - acc: 0.2448 - val_loss: 1.3859 - val_acc: 0.2505\n",
      "Epoch 4/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3822 - acc: 0.2636 - val_loss: 1.3774 - val_acc: 0.2681\n",
      "Epoch 5/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.3739 - acc: 0.2848 - val_loss: 1.3697 - val_acc: 0.2951\n",
      "Epoch 6/10\n",
      "1528/1528 [==============================] - 5s 4ms/step - loss: 1.3663 - acc: 0.3157 - val_loss: 1.3627 - val_acc: 0.3190\n",
      "Epoch 7/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3594 - acc: 0.3412 - val_loss: 1.3563 - val_acc: 0.3463\n",
      "Epoch 8/10\n",
      "1528/1528 [==============================] - 5s 4ms/step - loss: 1.3531 - acc: 0.3611 - val_loss: 1.3505 - val_acc: 0.3637\n",
      "Epoch 9/10\n",
      "1528/1528 [==============================] - 5s 4ms/step - loss: 1.3474 - acc: 0.3768 - val_loss: 1.3452 - val_acc: 0.3760\n",
      "Epoch 10/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3422 - acc: 0.3876 - val_loss: 1.3404 - val_acc: 0.3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████▏     | 19/46 [55:48<1:05:03, 144.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3055/3055 [==============================] - 18s 5ms/step - loss: 1.3147 - acc: 0.4045 - val_loss: 1.3129 - val_acc: 0.3972\n",
      "Epoch 2/3\n",
      "3055/3055 [==============================] - 15s 5ms/step - loss: 1.3103 - acc: 0.4045 - val_loss: 1.3120 - val_acc: 0.3972\n",
      "Epoch 3/3\n",
      "3055/3055 [==============================] - 15s 5ms/step - loss: 1.3096 - acc: 0.4045 - val_loss: 1.3115 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 20/46 [56:36<50:08, 115.72s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3055/3055 [==============================] - 16s 4ms/step - loss: 1.3612 - acc: 0.4040 - val_loss: 1.3519 - val_acc: 0.3972\n",
      "Epoch 2/3\n",
      "3055/3055 [==============================] - 11s 4ms/step - loss: 1.3415 - acc: 0.4045 - val_loss: 1.3371 - val_acc: 0.3972\n",
      "Epoch 3/3\n",
      "3055/3055 [==============================] - 11s 4ms/step - loss: 1.3299 - acc: 0.4045 - val_loss: 1.3284 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 21/46 [57:16<38:39, 92.77s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 31s 4ms/step - loss: 1.3818 - acc: 0.3690 - val_loss: 1.3767 - val_acc: 0.3972\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 29s 4ms/step - loss: 1.3714 - acc: 0.4045 - val_loss: 1.3671 - val_acc: 0.3972\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 32s 4ms/step - loss: 1.3620 - acc: 0.4045 - val_loss: 1.3584 - val_acc: 0.3972\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 33s 4ms/step - loss: 1.3535 - acc: 0.4045 - val_loss: 1.3506 - val_acc: 0.3972\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 28s 4ms/step - loss: 1.3460 - acc: 0.4045 - val_loss: 1.3438 - val_acc: 0.3972\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 27s 3ms/step - loss: 1.3395 - acc: 0.4045 - val_loss: 1.3379 - val_acc: 0.3972\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 27s 4ms/step - loss: 1.3339 - acc: 0.4045 - val_loss: 1.3330 - val_acc: 0.3972\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 27s 4ms/step - loss: 1.3292 - acc: 0.4045 - val_loss: 1.3289 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 27s 4ms/step - loss: 1.3253 - acc: 0.4045 - val_loss: 1.3255 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 26s 3ms/step - loss: 1.3221 - acc: 0.4045 - val_loss: 1.3228 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 22/46 [1:02:03<1:00:24, 151.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.4735 - acc: 0.1515 - val_loss: 1.4643 - val_acc: 0.1488\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.4508 - acc: 0.1543 - val_loss: 1.4441 - val_acc: 0.1483\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.4328 - acc: 0.1604 - val_loss: 1.4281 - val_acc: 0.1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 23/46 [1:03:13<48:37, 126.84s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.4629 - acc: 0.2298 - val_loss: 1.4502 - val_acc: 0.2333\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.4330 - acc: 0.2297 - val_loss: 1.4242 - val_acc: 0.2333\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.4100 - acc: 0.2297 - val_loss: 1.4038 - val_acc: 0.2334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 24/46 [1:04:20<39:58, 109.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1528/1528 [==============================] - 6s 3ms/step - loss: 1.5698 - acc: 0.1321 - val_loss: 1.5672 - val_acc: 0.1289\n",
      "Epoch 2/3\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.5641 - acc: 0.1321 - val_loss: 1.5616 - val_acc: 0.1289\n",
      "Epoch 3/3\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.5584 - acc: 0.1321 - val_loss: 1.5561 - val_acc: 0.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 25/46 [1:04:36<28:19, 80.92s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.7588 - acc: 0.2336 - val_loss: 1.7354 - val_acc: 0.2406\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.7103 - acc: 0.2336 - val_loss: 1.6899 - val_acc: 0.2406\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.6668 - acc: 0.2336 - val_loss: 1.6490 - val_acc: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 26/46 [1:05:38<25:08, 75.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 13s 3ms/step - loss: 1.3953 - acc: 0.2332 - val_loss: 1.3925 - val_acc: 0.2423\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3927 - acc: 0.2329 - val_loss: 1.3900 - val_acc: 0.2394\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3902 - acc: 0.2342 - val_loss: 1.3876 - val_acc: 0.2403\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3877 - acc: 0.2343 - val_loss: 1.3852 - val_acc: 0.2414\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3854 - acc: 0.2351 - val_loss: 1.3830 - val_acc: 0.2403\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 8s 3ms/step - loss: 1.3831 - acc: 0.2354 - val_loss: 1.3807 - val_acc: 0.2400\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3808 - acc: 0.2357 - val_loss: 1.3786 - val_acc: 0.2386\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3786 - acc: 0.2364 - val_loss: 1.3764 - val_acc: 0.2394\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3765 - acc: 0.2354 - val_loss: 1.3744 - val_acc: 0.2406\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3744 - acc: 0.2352 - val_loss: 1.3724 - val_acc: 0.2418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▊    | 27/46 [1:07:12<25:35, 80.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1528/1528 [==============================] - 8s 3ms/step - loss: 1.4652 - acc: 0.2287 - val_loss: 1.4519 - val_acc: 0.2331\n",
      "Epoch 2/3\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4456 - acc: 0.2296 - val_loss: 1.4343 - val_acc: 0.2331\n",
      "Epoch 3/3\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.4295 - acc: 0.2297 - val_loss: 1.4201 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████    | 28/46 [1:07:32<18:44, 62.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1528/1528 [==============================] - 6s 3ms/step - loss: 1.4540 - acc: 0.2298 - val_loss: 1.4500 - val_acc: 0.2333\n",
      "Epoch 2/3\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4516 - acc: 0.2298 - val_loss: 1.4477 - val_acc: 0.2333\n",
      "Epoch 3/3\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4493 - acc: 0.2298 - val_loss: 1.4455 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 29/46 [1:07:47<13:44, 48.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 11s 3ms/step - loss: 1.3399 - acc: 0.4045 - val_loss: 1.3443 - val_acc: 0.3972\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3366 - acc: 0.4045 - val_loss: 1.3409 - val_acc: 0.3972\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3337 - acc: 0.4045 - val_loss: 1.3378 - val_acc: 0.3972\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3310 - acc: 0.4045 - val_loss: 1.3351 - val_acc: 0.3972\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3287 - acc: 0.4045 - val_loss: 1.3326 - val_acc: 0.3972\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 8s 3ms/step - loss: 1.3266 - acc: 0.4045 - val_loss: 1.3304 - val_acc: 0.3972\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3247 - acc: 0.4045 - val_loss: 1.3285 - val_acc: 0.3972\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 8s 3ms/step - loss: 1.3231 - acc: 0.4045 - val_loss: 1.3267 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3216 - acc: 0.4045 - val_loss: 1.3251 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 8s 3ms/step - loss: 1.3202 - acc: 0.4045 - val_loss: 1.3236 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 30/46 [1:09:18<16:18, 61.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3861 - acc: 0.2309 - val_loss: 1.3639 - val_acc: 0.2388\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3483 - acc: 0.3070 - val_loss: 1.3368 - val_acc: 0.3888\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3274 - acc: 0.4053 - val_loss: 1.3220 - val_acc: 0.3972\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3158 - acc: 0.4045 - val_loss: 1.3138 - val_acc: 0.3972\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3093 - acc: 0.4045 - val_loss: 1.3092 - val_acc: 0.3972\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3055 - acc: 0.4045 - val_loss: 1.3063 - val_acc: 0.3972\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3030 - acc: 0.4045 - val_loss: 1.3045 - val_acc: 0.3972\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.3014 - acc: 0.4045 - val_loss: 1.3031 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3001 - acc: 0.4045 - val_loss: 1.3020 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.2990 - acc: 0.4045 - val_loss: 1.3010 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 31/46 [1:12:41<25:57, 103.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1528/1528 [==============================] - 8s 3ms/step - loss: 1.3840 - acc: 0.2722 - val_loss: 1.3765 - val_acc: 0.3020\n",
      "Epoch 2/3\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3717 - acc: 0.3320 - val_loss: 1.3653 - val_acc: 0.3506\n",
      "Epoch 3/3\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3611 - acc: 0.3695 - val_loss: 1.3555 - val_acc: 0.3753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████▉   | 32/46 [1:12:58<18:07, 77.70s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1528/1528 [==============================] - 9s 4ms/step - loss: 1.3869 - acc: 0.2283 - val_loss: 1.3844 - val_acc: 0.2537\n",
      "Epoch 2/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3818 - acc: 0.2885 - val_loss: 1.3796 - val_acc: 0.3126\n",
      "Epoch 3/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3771 - acc: 0.3510 - val_loss: 1.3751 - val_acc: 0.3654\n",
      "Epoch 4/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3725 - acc: 0.3935 - val_loss: 1.3706 - val_acc: 0.3932\n",
      "Epoch 5/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3681 - acc: 0.4024 - val_loss: 1.3662 - val_acc: 0.3958\n",
      "Epoch 6/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3636 - acc: 0.4045 - val_loss: 1.3619 - val_acc: 0.3973\n",
      "Epoch 7/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3592 - acc: 0.4045 - val_loss: 1.3575 - val_acc: 0.3972\n",
      "Epoch 8/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3547 - acc: 0.4045 - val_loss: 1.3531 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3502 - acc: 0.4045 - val_loss: 1.3487 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.3457 - acc: 0.4045 - val_loss: 1.3442 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 33/46 [1:14:00<15:48, 72.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 13s 3ms/step - loss: 1.3812 - acc: 0.4045 - val_loss: 1.3786 - val_acc: 0.3972\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3668 - acc: 0.4045 - val_loss: 1.3656 - val_acc: 0.3972\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3551 - acc: 0.4045 - val_loss: 1.3550 - val_acc: 0.3972\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3457 - acc: 0.4045 - val_loss: 1.3465 - val_acc: 0.3972\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.3381 - acc: 0.4045 - val_loss: 1.3396 - val_acc: 0.3972\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.3320 - acc: 0.4045 - val_loss: 1.3340 - val_acc: 0.3972\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3271 - acc: 0.4045 - val_loss: 1.3294 - val_acc: 0.3972\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3230 - acc: 0.4045 - val_loss: 1.3257 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3197 - acc: 0.4045 - val_loss: 1.3225 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3170 - acc: 0.4045 - val_loss: 1.3199 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 34/46 [1:15:38<16:06, 80.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 24s 3ms/step - loss: 1.3846 - acc: 0.2493 - val_loss: 1.3828 - val_acc: 0.3972\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3788 - acc: 0.4045 - val_loss: 1.3772 - val_acc: 0.3972\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3734 - acc: 0.4045 - val_loss: 1.3721 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 35/46 [1:16:44<13:55, 75.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 23s 3ms/step - loss: 1.6342 - acc: 0.1321 - val_loss: 1.6023 - val_acc: 0.1289\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.5661 - acc: 0.1321 - val_loss: 1.5405 - val_acc: 0.1289\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.5108 - acc: 0.1321 - val_loss: 1.4907 - val_acc: 0.1289\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.4664 - acc: 0.1321 - val_loss: 1.4511 - val_acc: 0.1289\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.4313 - acc: 0.1321 - val_loss: 1.4198 - val_acc: 0.1289\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.4037 - acc: 0.1526 - val_loss: 1.3953 - val_acc: 0.2214\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3822 - acc: 0.3298 - val_loss: 1.3763 - val_acc: 0.3874\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.3655 - acc: 0.4026 - val_loss: 1.3615 - val_acc: 0.3972\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3525 - acc: 0.4045 - val_loss: 1.3500 - val_acc: 0.3972\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3425 - acc: 0.4045 - val_loss: 1.3411 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 36/46 [1:20:09<19:07, 114.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1528/1528 [==============================] - 8s 3ms/step - loss: 1.3855 - acc: 0.2477 - val_loss: 1.3843 - val_acc: 0.2493\n",
      "Epoch 2/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3833 - acc: 0.2542 - val_loss: 1.3822 - val_acc: 0.2582\n",
      "Epoch 3/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3812 - acc: 0.2615 - val_loss: 1.3802 - val_acc: 0.2640\n",
      "Epoch 4/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3791 - acc: 0.2704 - val_loss: 1.3782 - val_acc: 0.2707\n",
      "Epoch 5/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.3771 - acc: 0.2793 - val_loss: 1.3762 - val_acc: 0.2817\n",
      "Epoch 6/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3751 - acc: 0.2889 - val_loss: 1.3743 - val_acc: 0.2904\n",
      "Epoch 7/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3731 - acc: 0.2988 - val_loss: 1.3724 - val_acc: 0.3025\n",
      "Epoch 8/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.3712 - acc: 0.3070 - val_loss: 1.3706 - val_acc: 0.3083\n",
      "Epoch 9/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3693 - acc: 0.3159 - val_loss: 1.3687 - val_acc: 0.3181\n",
      "Epoch 10/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3674 - acc: 0.3273 - val_loss: 1.3669 - val_acc: 0.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 37/46 [1:20:57<14:12, 94.69s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1528/1528 [==============================] - 8s 3ms/step - loss: 1.3911 - acc: 0.2452 - val_loss: 1.3887 - val_acc: 0.2495\n",
      "Epoch 2/3\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3871 - acc: 0.2565 - val_loss: 1.3850 - val_acc: 0.2618\n",
      "Epoch 3/3\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.3833 - acc: 0.2693 - val_loss: 1.3813 - val_acc: 0.2712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 38/46 [1:21:13<09:30, 71.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3055/3055 [==============================] - 14s 4ms/step - loss: 1.3964 - acc: 0.2298 - val_loss: 1.3673 - val_acc: 0.2333\n",
      "Epoch 2/3\n",
      "3055/3055 [==============================] - 11s 4ms/step - loss: 1.3533 - acc: 0.2453 - val_loss: 1.3384 - val_acc: 0.3972\n",
      "Epoch 3/3\n",
      "3055/3055 [==============================] - 11s 3ms/step - loss: 1.3314 - acc: 0.4045 - val_loss: 1.3245 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▍ | 39/46 [1:21:50<07:06, 60.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.3710 - acc: 0.4045 - val_loss: 1.3701 - val_acc: 0.3972\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.3679 - acc: 0.4045 - val_loss: 1.3671 - val_acc: 0.3972\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3649 - acc: 0.4045 - val_loss: 1.3643 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 40/46 [1:22:59<06:19, 63.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 12s 3ms/step - loss: 2.1862 - acc: 0.1321 - val_loss: 2.1535 - val_acc: 0.1289\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 2.1215 - acc: 0.1321 - val_loss: 2.0905 - val_acc: 0.1289\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 2.0602 - acc: 0.1321 - val_loss: 2.0309 - val_acc: 0.1289\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 2.0027 - acc: 0.1321 - val_loss: 1.9750 - val_acc: 0.1289\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.9482 - acc: 0.1321 - val_loss: 1.9220 - val_acc: 0.1289\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 12s 4ms/step - loss: 1.8969 - acc: 0.1321 - val_loss: 1.8723 - val_acc: 0.1289\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.8489 - acc: 0.1321 - val_loss: 1.8257 - val_acc: 0.1289\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 11s 4ms/step - loss: 1.8038 - acc: 0.1321 - val_loss: 1.7820 - val_acc: 0.1289\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 12s 4ms/step - loss: 1.7615 - acc: 0.1321 - val_loss: 1.7411 - val_acc: 0.1289\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 12s 4ms/step - loss: 1.7219 - acc: 0.1321 - val_loss: 1.7029 - val_acc: 0.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 41/46 [1:24:48<06:24, 76.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.3607 - acc: 0.2336 - val_loss: 1.3556 - val_acc: 0.2406\n",
      "Epoch 2/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3584 - acc: 0.2336 - val_loss: 1.3535 - val_acc: 0.2406\n",
      "Epoch 3/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3563 - acc: 0.2336 - val_loss: 1.3515 - val_acc: 0.2406\n",
      "Epoch 4/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3542 - acc: 0.2336 - val_loss: 1.3496 - val_acc: 0.2406\n",
      "Epoch 5/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3522 - acc: 0.2336 - val_loss: 1.3478 - val_acc: 0.2406\n",
      "Epoch 6/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3503 - acc: 0.2336 - val_loss: 1.3461 - val_acc: 0.2406\n",
      "Epoch 7/10\n",
      "7636/7636 [==============================] - 21s 3ms/step - loss: 1.3485 - acc: 0.2336 - val_loss: 1.3445 - val_acc: 0.2406\n",
      "Epoch 8/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3468 - acc: 0.2336 - val_loss: 1.3429 - val_acc: 0.2406\n",
      "Epoch 9/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3452 - acc: 0.2336 - val_loss: 1.3414 - val_acc: 0.2406\n",
      "Epoch 10/10\n",
      "7636/7636 [==============================] - 20s 3ms/step - loss: 1.3436 - acc: 0.2336 - val_loss: 1.3400 - val_acc: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████▏| 42/46 [1:28:15<07:43, 115.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7636/7636 [==============================] - 25s 3ms/step - loss: 1.3551 - acc: 0.4045 - val_loss: 1.3540 - val_acc: 0.3972\n",
      "Epoch 2/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3437 - acc: 0.4045 - val_loss: 1.3439 - val_acc: 0.3972\n",
      "Epoch 3/3\n",
      "7636/7636 [==============================] - 22s 3ms/step - loss: 1.3350 - acc: 0.4045 - val_loss: 1.3362 - val_acc: 0.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 43/46 [1:29:24<05:05, 101.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3055/3055 [==============================] - 12s 3ms/step - loss: 1.4744 - acc: 0.1727 - val_loss: 1.4523 - val_acc: 0.1801\n",
      "Epoch 2/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.4372 - acc: 0.1894 - val_loss: 1.4202 - val_acc: 0.1965\n",
      "Epoch 3/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.4088 - acc: 0.2099 - val_loss: 1.3953 - val_acc: 0.2382\n",
      "Epoch 4/10\n",
      "3055/3055 [==============================] - 8s 3ms/step - loss: 1.3865 - acc: 0.2619 - val_loss: 1.3756 - val_acc: 0.3089\n",
      "Epoch 5/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3687 - acc: 0.3404 - val_loss: 1.3598 - val_acc: 0.3729\n",
      "Epoch 6/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3543 - acc: 0.3947 - val_loss: 1.3470 - val_acc: 0.4010\n",
      "Epoch 7/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3425 - acc: 0.4117 - val_loss: 1.3364 - val_acc: 0.4030\n",
      "Epoch 8/10\n",
      "3055/3055 [==============================] - 8s 3ms/step - loss: 1.3328 - acc: 0.4081 - val_loss: 1.3278 - val_acc: 0.3983\n",
      "Epoch 9/10\n",
      "3055/3055 [==============================] - 10s 3ms/step - loss: 1.3249 - acc: 0.4056 - val_loss: 1.3207 - val_acc: 0.3976\n",
      "Epoch 10/10\n",
      "3055/3055 [==============================] - 9s 3ms/step - loss: 1.3183 - acc: 0.4050 - val_loss: 1.3148 - val_acc: 0.3973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 44/46 [1:30:55<03:17, 98.72s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1528/1528 [==============================] - 7s 3ms/step - loss: 1.4151 - acc: 0.1359 - val_loss: 1.4164 - val_acc: 0.1317\n",
      "Epoch 2/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4137 - acc: 0.1401 - val_loss: 1.4149 - val_acc: 0.1355\n",
      "Epoch 3/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4122 - acc: 0.1460 - val_loss: 1.4135 - val_acc: 0.1416\n",
      "Epoch 4/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4108 - acc: 0.1543 - val_loss: 1.4120 - val_acc: 0.1526\n",
      "Epoch 5/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4094 - acc: 0.1683 - val_loss: 1.4106 - val_acc: 0.1696\n",
      "Epoch 6/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4080 - acc: 0.1869 - val_loss: 1.4093 - val_acc: 0.1856\n",
      "Epoch 7/10\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.4066 - acc: 0.2103 - val_loss: 1.4079 - val_acc: 0.2076\n",
      "Epoch 8/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4053 - acc: 0.2338 - val_loss: 1.4066 - val_acc: 0.2279\n",
      "Epoch 9/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4040 - acc: 0.2611 - val_loss: 1.4053 - val_acc: 0.2548\n",
      "Epoch 10/10\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 1.4027 - acc: 0.2861 - val_loss: 1.4041 - val_acc: 0.2797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 45/46 [1:31:41<01:22, 82.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1528/1528 [==============================] - 10s 4ms/step - loss: 1.6265 - acc: 0.2298 - val_loss: 1.5987 - val_acc: 0.2333\n",
      "Epoch 2/3\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 1.5715 - acc: 0.2298 - val_loss: 1.5476 - val_acc: 0.2333\n",
      "Epoch 3/3\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 1.5235 - acc: 0.2298 - val_loss: 1.5031 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 46/46 [1:32:03<00:00, 120.07s/it][A\n"
     ]
    }
   ],
   "source": [
    "scan_object = talos.Scan(x,\n",
    "                         y, \n",
    "                         params=p,\n",
    "                         model=OSA_model,\n",
    "                         experiment_name='OSA_hyper_lstm',\n",
    "                         fraction_limit=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65b7b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_object = talos.Analyze(scan_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "da388ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>lr</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>loss</th>\n",
       "      <th>first_activation</th>\n",
       "      <th>second_activation</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>weight_regulizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07/13/22-025220</td>\n",
       "      <td>07/13/22-025511</td>\n",
       "      <td>170.910510</td>\n",
       "      <td>3</td>\n",
       "      <td>1.418400</td>\n",
       "      <td>0.233565</td>\n",
       "      <td>1.400816</td>\n",
       "      <td>0.240605</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/13/22-025512</td>\n",
       "      <td>07/13/22-030155</td>\n",
       "      <td>402.885345</td>\n",
       "      <td>10</td>\n",
       "      <td>2.076251</td>\n",
       "      <td>0.229767</td>\n",
       "      <td>2.039679</td>\n",
       "      <td>0.233272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07/13/22-030156</td>\n",
       "      <td>07/13/22-030401</td>\n",
       "      <td>125.277733</td>\n",
       "      <td>3</td>\n",
       "      <td>1.377966</td>\n",
       "      <td>0.333421</td>\n",
       "      <td>1.377525</td>\n",
       "      <td>0.339444</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/13/22-030402</td>\n",
       "      <td>07/13/22-031101</td>\n",
       "      <td>418.231230</td>\n",
       "      <td>10</td>\n",
       "      <td>1.358620</td>\n",
       "      <td>0.370285</td>\n",
       "      <td>1.358256</td>\n",
       "      <td>0.380232</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07/13/22-031102</td>\n",
       "      <td>07/13/22-031801</td>\n",
       "      <td>419.018404</td>\n",
       "      <td>10</td>\n",
       "      <td>1.380661</td>\n",
       "      <td>0.233434</td>\n",
       "      <td>1.377626</td>\n",
       "      <td>0.241522</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07/13/22-031802</td>\n",
       "      <td>07/13/22-032120</td>\n",
       "      <td>197.309680</td>\n",
       "      <td>10</td>\n",
       "      <td>1.329286</td>\n",
       "      <td>0.402370</td>\n",
       "      <td>1.327125</td>\n",
       "      <td>0.394745</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>relu</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07/13/22-032121</td>\n",
       "      <td>07/13/22-032341</td>\n",
       "      <td>139.717812</td>\n",
       "      <td>10</td>\n",
       "      <td>1.523960</td>\n",
       "      <td>0.229767</td>\n",
       "      <td>1.512460</td>\n",
       "      <td>0.233272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>07/13/22-032341</td>\n",
       "      <td>07/13/22-032445</td>\n",
       "      <td>64.422050</td>\n",
       "      <td>3</td>\n",
       "      <td>1.386097</td>\n",
       "      <td>0.268596</td>\n",
       "      <td>1.385063</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>07/13/22-032446</td>\n",
       "      <td>07/13/22-032647</td>\n",
       "      <td>120.890296</td>\n",
       "      <td>10</td>\n",
       "      <td>1.343736</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.338792</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.28</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softmax</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>07/13/22-032647</td>\n",
       "      <td>07/13/22-032822</td>\n",
       "      <td>95.124956</td>\n",
       "      <td>10</td>\n",
       "      <td>1.375772</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.375213</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.28</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softsign</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>07/13/22-032823</td>\n",
       "      <td>07/13/22-032843</td>\n",
       "      <td>20.991175</td>\n",
       "      <td>3</td>\n",
       "      <td>1.401848</td>\n",
       "      <td>0.215623</td>\n",
       "      <td>1.395571</td>\n",
       "      <td>0.238313</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>tanh</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>07/13/22-032844</td>\n",
       "      <td>07/13/22-033234</td>\n",
       "      <td>230.470400</td>\n",
       "      <td>10</td>\n",
       "      <td>1.359686</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.359615</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softsign</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>07/13/22-033235</td>\n",
       "      <td>07/13/22-033324</td>\n",
       "      <td>48.994585</td>\n",
       "      <td>10</td>\n",
       "      <td>1.379144</td>\n",
       "      <td>0.229767</td>\n",
       "      <td>1.374627</td>\n",
       "      <td>0.233119</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>07/13/22-033324</td>\n",
       "      <td>07/13/22-033351</td>\n",
       "      <td>26.392659</td>\n",
       "      <td>3</td>\n",
       "      <td>1.320732</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.318906</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softsign</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>07/13/22-033351</td>\n",
       "      <td>07/13/22-033750</td>\n",
       "      <td>239.074420</td>\n",
       "      <td>10</td>\n",
       "      <td>1.305396</td>\n",
       "      <td>0.404728</td>\n",
       "      <td>1.307206</td>\n",
       "      <td>0.397036</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>07/13/22-033750</td>\n",
       "      <td>07/13/22-033845</td>\n",
       "      <td>54.127797</td>\n",
       "      <td>10</td>\n",
       "      <td>1.483747</td>\n",
       "      <td>0.233565</td>\n",
       "      <td>1.474931</td>\n",
       "      <td>0.240605</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softsign</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>07/13/22-033845</td>\n",
       "      <td>07/13/22-034316</td>\n",
       "      <td>271.032686</td>\n",
       "      <td>10</td>\n",
       "      <td>1.298239</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.300035</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>07/13/22-034317</td>\n",
       "      <td>07/13/22-034706</td>\n",
       "      <td>229.861710</td>\n",
       "      <td>10</td>\n",
       "      <td>1.301615</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.304186</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softsign</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>07/13/22-034707</td>\n",
       "      <td>07/13/22-034808</td>\n",
       "      <td>61.171921</td>\n",
       "      <td>10</td>\n",
       "      <td>1.342187</td>\n",
       "      <td>0.387572</td>\n",
       "      <td>1.340418</td>\n",
       "      <td>0.385732</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>tanh</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>07/13/22-034808</td>\n",
       "      <td>07/13/22-034856</td>\n",
       "      <td>47.950788</td>\n",
       "      <td>3</td>\n",
       "      <td>1.309610</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.311530</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>07/13/22-034857</td>\n",
       "      <td>07/13/22-034936</td>\n",
       "      <td>38.902034</td>\n",
       "      <td>3</td>\n",
       "      <td>1.329896</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.328435</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>07/13/22-034936</td>\n",
       "      <td>07/13/22-035423</td>\n",
       "      <td>286.549053</td>\n",
       "      <td>10</td>\n",
       "      <td>1.322141</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.322817</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softmax</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>07/13/22-035423</td>\n",
       "      <td>07/13/22-035533</td>\n",
       "      <td>70.081099</td>\n",
       "      <td>3</td>\n",
       "      <td>1.432840</td>\n",
       "      <td>0.160359</td>\n",
       "      <td>1.428070</td>\n",
       "      <td>0.151543</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>07/13/22-035533</td>\n",
       "      <td>07/13/22-035640</td>\n",
       "      <td>67.060629</td>\n",
       "      <td>3</td>\n",
       "      <td>1.409954</td>\n",
       "      <td>0.229701</td>\n",
       "      <td>1.403827</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>07/13/22-035641</td>\n",
       "      <td>07/13/22-035656</td>\n",
       "      <td>15.089117</td>\n",
       "      <td>3</td>\n",
       "      <td>1.558436</td>\n",
       "      <td>0.132137</td>\n",
       "      <td>1.556118</td>\n",
       "      <td>0.128934</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>07/13/22-035656</td>\n",
       "      <td>07/13/22-035758</td>\n",
       "      <td>62.160553</td>\n",
       "      <td>3</td>\n",
       "      <td>1.666807</td>\n",
       "      <td>0.233565</td>\n",
       "      <td>1.649005</td>\n",
       "      <td>0.240605</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>07/13/22-035759</td>\n",
       "      <td>07/13/22-035932</td>\n",
       "      <td>93.016002</td>\n",
       "      <td>10</td>\n",
       "      <td>1.374369</td>\n",
       "      <td>0.235202</td>\n",
       "      <td>1.372364</td>\n",
       "      <td>0.241827</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>07/13/22-035932</td>\n",
       "      <td>07/13/22-035951</td>\n",
       "      <td>19.351465</td>\n",
       "      <td>3</td>\n",
       "      <td>1.429506</td>\n",
       "      <td>0.229701</td>\n",
       "      <td>1.420078</td>\n",
       "      <td>0.233272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>07/13/22-035952</td>\n",
       "      <td>07/13/22-040007</td>\n",
       "      <td>15.541355</td>\n",
       "      <td>3</td>\n",
       "      <td>1.449337</td>\n",
       "      <td>0.229767</td>\n",
       "      <td>1.445474</td>\n",
       "      <td>0.233272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>07/13/22-040008</td>\n",
       "      <td>07/13/22-040138</td>\n",
       "      <td>90.332895</td>\n",
       "      <td>10</td>\n",
       "      <td>1.320222</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.323620</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>relu</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>07/13/22-040138</td>\n",
       "      <td>07/13/22-040501</td>\n",
       "      <td>202.974705</td>\n",
       "      <td>10</td>\n",
       "      <td>1.299007</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.301006</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>07/13/22-040502</td>\n",
       "      <td>07/13/22-040518</td>\n",
       "      <td>16.437951</td>\n",
       "      <td>3</td>\n",
       "      <td>1.361076</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>1.355471</td>\n",
       "      <td>0.375344</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>07/13/22-040518</td>\n",
       "      <td>07/13/22-040620</td>\n",
       "      <td>61.315833</td>\n",
       "      <td>10</td>\n",
       "      <td>1.345679</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.344236</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>07/13/22-040620</td>\n",
       "      <td>07/13/22-040758</td>\n",
       "      <td>97.900557</td>\n",
       "      <td>10</td>\n",
       "      <td>1.316984</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.319938</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>07/13/22-040759</td>\n",
       "      <td>07/13/22-040904</td>\n",
       "      <td>64.955214</td>\n",
       "      <td>3</td>\n",
       "      <td>1.373414</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.372121</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>07/13/22-040904</td>\n",
       "      <td>07/13/22-041229</td>\n",
       "      <td>204.901033</td>\n",
       "      <td>10</td>\n",
       "      <td>1.342482</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.341098</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>07/13/22-041229</td>\n",
       "      <td>07/13/22-041317</td>\n",
       "      <td>47.544808</td>\n",
       "      <td>10</td>\n",
       "      <td>1.367416</td>\n",
       "      <td>0.327331</td>\n",
       "      <td>1.366912</td>\n",
       "      <td>0.326764</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softsign</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>07/13/22-041317</td>\n",
       "      <td>07/13/22-041333</td>\n",
       "      <td>16.369225</td>\n",
       "      <td>3</td>\n",
       "      <td>1.383261</td>\n",
       "      <td>0.269251</td>\n",
       "      <td>1.381345</td>\n",
       "      <td>0.271158</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>relu</td>\n",
       "      <td>softsign</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>07/13/22-041334</td>\n",
       "      <td>07/13/22-041410</td>\n",
       "      <td>36.143863</td>\n",
       "      <td>3</td>\n",
       "      <td>1.331355</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.324535</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>07/13/22-041410</td>\n",
       "      <td>07/13/22-041519</td>\n",
       "      <td>68.358095</td>\n",
       "      <td>3</td>\n",
       "      <td>1.364911</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.364268</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>07/13/22-041519</td>\n",
       "      <td>07/13/22-041707</td>\n",
       "      <td>108.339176</td>\n",
       "      <td>10</td>\n",
       "      <td>1.721907</td>\n",
       "      <td>0.132137</td>\n",
       "      <td>1.702868</td>\n",
       "      <td>0.128934</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>07/13/22-041708</td>\n",
       "      <td>07/13/22-042034</td>\n",
       "      <td>206.576968</td>\n",
       "      <td>10</td>\n",
       "      <td>1.343599</td>\n",
       "      <td>0.233565</td>\n",
       "      <td>1.339993</td>\n",
       "      <td>0.240605</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.28</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>07/13/22-042035</td>\n",
       "      <td>07/13/22-042143</td>\n",
       "      <td>68.619779</td>\n",
       "      <td>3</td>\n",
       "      <td>1.335044</td>\n",
       "      <td>0.404531</td>\n",
       "      <td>1.336228</td>\n",
       "      <td>0.397189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.28</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softplus</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>07/13/22-042144</td>\n",
       "      <td>07/13/22-042315</td>\n",
       "      <td>91.020877</td>\n",
       "      <td>10</td>\n",
       "      <td>1.318287</td>\n",
       "      <td>0.404990</td>\n",
       "      <td>1.314848</td>\n",
       "      <td>0.397342</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>linear</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>07/13/22-042315</td>\n",
       "      <td>07/13/22-042401</td>\n",
       "      <td>45.597369</td>\n",
       "      <td>10</td>\n",
       "      <td>1.402727</td>\n",
       "      <td>0.286145</td>\n",
       "      <td>1.404062</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>softmax</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>07/13/22-042401</td>\n",
       "      <td>07/13/22-042422</td>\n",
       "      <td>21.268966</td>\n",
       "      <td>3</td>\n",
       "      <td>1.523463</td>\n",
       "      <td>0.229767</td>\n",
       "      <td>1.503098</td>\n",
       "      <td>0.233272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>&lt;class 'keras.optimizers.optimizer_v2.nadam.Na...</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>tanh</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end    duration  round_epochs      loss  \\\n",
       "0   07/13/22-025220  07/13/22-025511  170.910510             3  1.418400   \n",
       "1   07/13/22-025512  07/13/22-030155  402.885345            10  2.076251   \n",
       "2   07/13/22-030156  07/13/22-030401  125.277733             3  1.377966   \n",
       "3   07/13/22-030402  07/13/22-031101  418.231230            10  1.358620   \n",
       "4   07/13/22-031102  07/13/22-031801  419.018404            10  1.380661   \n",
       "5   07/13/22-031802  07/13/22-032120  197.309680            10  1.329286   \n",
       "6   07/13/22-032121  07/13/22-032341  139.717812            10  1.523960   \n",
       "7   07/13/22-032341  07/13/22-032445   64.422050             3  1.386097   \n",
       "8   07/13/22-032446  07/13/22-032647  120.890296            10  1.343736   \n",
       "9   07/13/22-032647  07/13/22-032822   95.124956            10  1.375772   \n",
       "10  07/13/22-032823  07/13/22-032843   20.991175             3  1.401848   \n",
       "11  07/13/22-032844  07/13/22-033234  230.470400            10  1.359686   \n",
       "12  07/13/22-033235  07/13/22-033324   48.994585            10  1.379144   \n",
       "13  07/13/22-033324  07/13/22-033351   26.392659             3  1.320732   \n",
       "14  07/13/22-033351  07/13/22-033750  239.074420            10  1.305396   \n",
       "15  07/13/22-033750  07/13/22-033845   54.127797            10  1.483747   \n",
       "16  07/13/22-033845  07/13/22-034316  271.032686            10  1.298239   \n",
       "17  07/13/22-034317  07/13/22-034706  229.861710            10  1.301615   \n",
       "18  07/13/22-034707  07/13/22-034808   61.171921            10  1.342187   \n",
       "19  07/13/22-034808  07/13/22-034856   47.950788             3  1.309610   \n",
       "20  07/13/22-034857  07/13/22-034936   38.902034             3  1.329896   \n",
       "21  07/13/22-034936  07/13/22-035423  286.549053            10  1.322141   \n",
       "22  07/13/22-035423  07/13/22-035533   70.081099             3  1.432840   \n",
       "23  07/13/22-035533  07/13/22-035640   67.060629             3  1.409954   \n",
       "24  07/13/22-035641  07/13/22-035656   15.089117             3  1.558436   \n",
       "25  07/13/22-035656  07/13/22-035758   62.160553             3  1.666807   \n",
       "26  07/13/22-035759  07/13/22-035932   93.016002            10  1.374369   \n",
       "27  07/13/22-035932  07/13/22-035951   19.351465             3  1.429506   \n",
       "28  07/13/22-035952  07/13/22-040007   15.541355             3  1.449337   \n",
       "29  07/13/22-040008  07/13/22-040138   90.332895            10  1.320222   \n",
       "30  07/13/22-040138  07/13/22-040501  202.974705            10  1.299007   \n",
       "31  07/13/22-040502  07/13/22-040518   16.437951             3  1.361076   \n",
       "32  07/13/22-040518  07/13/22-040620   61.315833            10  1.345679   \n",
       "33  07/13/22-040620  07/13/22-040758   97.900557            10  1.316984   \n",
       "34  07/13/22-040759  07/13/22-040904   64.955214             3  1.373414   \n",
       "35  07/13/22-040904  07/13/22-041229  204.901033            10  1.342482   \n",
       "36  07/13/22-041229  07/13/22-041317   47.544808            10  1.367416   \n",
       "37  07/13/22-041317  07/13/22-041333   16.369225             3  1.383261   \n",
       "38  07/13/22-041334  07/13/22-041410   36.143863             3  1.331355   \n",
       "39  07/13/22-041410  07/13/22-041519   68.358095             3  1.364911   \n",
       "40  07/13/22-041519  07/13/22-041707  108.339176            10  1.721907   \n",
       "41  07/13/22-041708  07/13/22-042034  206.576968            10  1.343599   \n",
       "42  07/13/22-042035  07/13/22-042143   68.619779             3  1.335044   \n",
       "43  07/13/22-042144  07/13/22-042315   91.020877            10  1.318287   \n",
       "44  07/13/22-042315  07/13/22-042401   45.597369            10  1.402727   \n",
       "45  07/13/22-042401  07/13/22-042422   21.268966             3  1.523463   \n",
       "\n",
       "         acc  val_loss   val_acc     lr  first_neuron  batch_size  epochs  \\\n",
       "0   0.233565  1.400816  0.240605  0.001            32           5       3   \n",
       "1   0.229767  2.039679  0.233272  0.001            16           5      10   \n",
       "2   0.333421  1.377525  0.339444  0.001             4           5       3   \n",
       "3   0.370285  1.358256  0.380232  0.001             4           5      10   \n",
       "4   0.233434  1.377626  0.241522  0.001             4           5      10   \n",
       "5   0.402370  1.327125  0.394745  0.001            16          10      10   \n",
       "6   0.229767  1.512460  0.233272  0.001             4           5      10   \n",
       "7   0.268596  1.385063  0.286587  0.001             4           2       3   \n",
       "8   0.404531  1.338792  0.397189  0.001            64           5      10   \n",
       "9   0.404531  1.375213  0.397189  0.001            16           5      10   \n",
       "10  0.215623  1.395571  0.238313  0.001             8          10       3   \n",
       "11  0.404531  1.359615  0.397189  0.001             4           2      10   \n",
       "12  0.229767  1.374627  0.233119  0.001            16          10      10   \n",
       "13  0.404531  1.318906  0.397189  0.001           128          10       3   \n",
       "14  0.404728  1.307206  0.397036  0.001            32           2      10   \n",
       "15  0.233565  1.474931  0.240605  0.001            16          10      10   \n",
       "16  0.404531  1.300035  0.397189  0.001            64           2      10   \n",
       "17  0.404531  1.304186  0.397189  0.001            32           2      10   \n",
       "18  0.387572  1.340418  0.385732  0.001            16          10      10   \n",
       "19  0.404531  1.311530  0.397189  0.001           128           5       3   \n",
       "20  0.404531  1.328435  0.397189  0.001            64           5       3   \n",
       "21  0.404531  1.322817  0.397189  0.001           128           2      10   \n",
       "22  0.160359  1.428070  0.151543  0.001             8           2       3   \n",
       "23  0.229701  1.403827  0.233425  0.001            16           2       3   \n",
       "24  0.132137  1.556118  0.128934  0.001             8          10       3   \n",
       "25  0.233565  1.649005  0.240605  0.001             8           2       3   \n",
       "26  0.235202  1.372364  0.241827  0.001             4           5      10   \n",
       "27  0.229701  1.420078  0.233272  0.001            32          10       3   \n",
       "28  0.229767  1.445474  0.233272  0.001             4          10       3   \n",
       "29  0.404531  1.323620  0.397189  0.001            16           5      10   \n",
       "30  0.404531  1.301006  0.397189  0.001            32           2      10   \n",
       "31  0.369500  1.355471  0.375344  0.001            16          10       3   \n",
       "32  0.404531  1.344236  0.397189  0.001           128          10      10   \n",
       "33  0.404531  1.319938  0.397189  0.001            16           5      10   \n",
       "34  0.404531  1.372121  0.397189  0.001            16           2       3   \n",
       "35  0.404531  1.341098  0.397189  0.001            16           2      10   \n",
       "36  0.327331  1.366912  0.326764  0.001             4          10      10   \n",
       "37  0.269251  1.381345  0.271158  0.001             8          10       3   \n",
       "38  0.404531  1.324535  0.397189  0.001           128           5       3   \n",
       "39  0.404531  1.364268  0.397189  0.001            32           2       3   \n",
       "40  0.132137  1.702868  0.128934  0.001            16           5      10   \n",
       "41  0.233565  1.339993  0.240605  0.001             4           2      10   \n",
       "42  0.404531  1.336228  0.397189  0.001            16           2       3   \n",
       "43  0.404990  1.314848  0.397342  0.001            16           5      10   \n",
       "44  0.286145  1.404062  0.279713  0.001             4          10      10   \n",
       "45  0.229767  1.503098  0.233272  0.001            32          10       3   \n",
       "\n",
       "    dropout                                          optimizer  \\\n",
       "0      0.20  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "1      0.32  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "2      0.28  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "3      0.16  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "4      0.24  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "5      0.08  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "6      0.32  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "7      0.08  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "8      0.28  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "9      0.28  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "10     0.04  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "11     0.12  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "12     0.24  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "13     0.24  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "14     0.00  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "15     0.12  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "16     0.36  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "17     0.24  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "18     0.36  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "19     0.24  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "20     0.32  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "21     0.16  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "22     0.36  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "23     0.24  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "24     0.08  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "25     0.00  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "26     0.12  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "27     0.32  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "28     0.08  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "29     0.08  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "30     0.04  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "31     0.04  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "32     0.08  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "33     0.32  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "34     0.00  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "35     0.08  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "36     0.12  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "37     0.04  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "38     0.20  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "39     0.24  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "40     0.36  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "41     0.28  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "42     0.28  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "43     0.04  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "44     0.32  <class 'keras.optimizers.optimizer_v2.adam.Adam'>   \n",
       "45     0.00  <class 'keras.optimizers.optimizer_v2.nadam.Na...   \n",
       "\n",
       "                        loss first_activation second_activation  \\\n",
       "0   categorical_crossentropy           linear      hard_sigmoid   \n",
       "1   categorical_crossentropy          softmax          softplus   \n",
       "2   categorical_crossentropy          sigmoid              tanh   \n",
       "3   categorical_crossentropy     hard_sigmoid            linear   \n",
       "4   categorical_crossentropy         softplus      hard_sigmoid   \n",
       "5   categorical_crossentropy             relu            linear   \n",
       "6   categorical_crossentropy          sigmoid          softplus   \n",
       "7   categorical_crossentropy           linear              relu   \n",
       "8   categorical_crossentropy          softmax      hard_sigmoid   \n",
       "9   categorical_crossentropy          softmax          softsign   \n",
       "10  categorical_crossentropy             tanh              tanh   \n",
       "11  categorical_crossentropy          softmax          softsign   \n",
       "12  categorical_crossentropy          sigmoid          softplus   \n",
       "13  categorical_crossentropy         softsign          softplus   \n",
       "14  categorical_crossentropy           linear           sigmoid   \n",
       "15  categorical_crossentropy         softsign      hard_sigmoid   \n",
       "16  categorical_crossentropy          sigmoid            linear   \n",
       "17  categorical_crossentropy         softplus          softsign   \n",
       "18  categorical_crossentropy             tanh            linear   \n",
       "19  categorical_crossentropy         softplus           sigmoid   \n",
       "20  categorical_crossentropy     hard_sigmoid              relu   \n",
       "21  categorical_crossentropy          softmax            linear   \n",
       "22  categorical_crossentropy     hard_sigmoid            linear   \n",
       "23  categorical_crossentropy     hard_sigmoid            linear   \n",
       "24  categorical_crossentropy           linear           sigmoid   \n",
       "25  categorical_crossentropy         softplus          softplus   \n",
       "26  categorical_crossentropy           linear      hard_sigmoid   \n",
       "27  categorical_crossentropy     hard_sigmoid              relu   \n",
       "28  categorical_crossentropy          sigmoid      hard_sigmoid   \n",
       "29  categorical_crossentropy             relu          softplus   \n",
       "30  categorical_crossentropy         softplus              relu   \n",
       "31  categorical_crossentropy           linear            linear   \n",
       "32  categorical_crossentropy             relu              relu   \n",
       "33  categorical_crossentropy         softplus      hard_sigmoid   \n",
       "34  categorical_crossentropy          sigmoid           softmax   \n",
       "35  categorical_crossentropy         softplus           sigmoid   \n",
       "36  categorical_crossentropy         softsign              tanh   \n",
       "37  categorical_crossentropy             relu          softsign   \n",
       "38  categorical_crossentropy          softmax          softplus   \n",
       "39  categorical_crossentropy          softmax           softmax   \n",
       "40  categorical_crossentropy     hard_sigmoid          softplus   \n",
       "41  categorical_crossentropy          sigmoid      hard_sigmoid   \n",
       "42  categorical_crossentropy         softplus      hard_sigmoid   \n",
       "43  categorical_crossentropy           linear              tanh   \n",
       "44  categorical_crossentropy          softmax              tanh   \n",
       "45  categorical_crossentropy             tanh          softplus   \n",
       "\n",
       "   last_activation weight_regulizer  \n",
       "0          softmax             None  \n",
       "1          softmax             None  \n",
       "2          softmax             None  \n",
       "3          softmax             None  \n",
       "4          softmax             None  \n",
       "5          softmax             None  \n",
       "6          softmax             None  \n",
       "7          softmax             None  \n",
       "8          softmax             None  \n",
       "9          softmax             None  \n",
       "10         softmax             None  \n",
       "11         softmax             None  \n",
       "12         softmax             None  \n",
       "13         softmax             None  \n",
       "14         softmax             None  \n",
       "15         softmax             None  \n",
       "16         softmax             None  \n",
       "17         softmax             None  \n",
       "18         softmax             None  \n",
       "19         softmax             None  \n",
       "20         softmax             None  \n",
       "21         softmax             None  \n",
       "22         softmax             None  \n",
       "23         softmax             None  \n",
       "24         softmax             None  \n",
       "25         softmax             None  \n",
       "26         softmax             None  \n",
       "27         softmax             None  \n",
       "28         softmax             None  \n",
       "29         softmax             None  \n",
       "30         softmax             None  \n",
       "31         softmax             None  \n",
       "32         softmax             None  \n",
       "33         softmax             None  \n",
       "34         softmax             None  \n",
       "35         softmax             None  \n",
       "36         softmax             None  \n",
       "37         softmax             None  \n",
       "38         softmax             None  \n",
       "39         softmax             None  \n",
       "40         softmax             None  \n",
       "41         softmax             None  \n",
       "42         softmax             None  \n",
       "43         softmax             None  \n",
       "44         softmax             None  \n",
       "45         softmax             None  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_object.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "887c8629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39734187722206116"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_object.high('val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "28aefee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_object.rounds2high('val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12c3499a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start                                                  07/13/22-042144\n",
       "end                                                    07/13/22-042315\n",
       "duration                                                     91.020877\n",
       "round_epochs                                                        10\n",
       "loss                                                          1.318287\n",
       "acc                                                            0.40499\n",
       "val_loss                                                      1.314848\n",
       "val_acc                                                       0.397342\n",
       "lr                                                               0.001\n",
       "first_neuron                                                        16\n",
       "batch_size                                                           5\n",
       "epochs                                                              10\n",
       "dropout                                                           0.04\n",
       "optimizer            <class 'keras.optimizers.optimizer_v2.nadam.Na...\n",
       "loss                                          categorical_crossentropy\n",
       "first_activation                                                linear\n",
       "second_activation                                                 tanh\n",
       "last_activation                                                softmax\n",
       "weight_regulizer                                                  None\n",
       "Name: 43, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= analyze_object.rounds2high('val_acc')\n",
    "analyze_object.data.loc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f138d2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['tanh', 10, '07/13/22-042144', 16,\n",
       "        <class 'keras.optimizers.optimizer_v2.nadam.Nadam'>, 'softmax',\n",
       "        '07/13/22-042315', 0.04, 10, 91.02087736129761, 'linear', 5,\n",
       "        None, 0.001, 0]], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_object.best_params('val_acc', ['acc', 'loss', 'val_loss'], n =1) \n",
    "# the 1st parameter is the metric youre interested in, the 2nd parameter is the metrics you want excluded, it runs 10 scans by defualt, but you can change this to n = #\n",
    "# this returns the parameters for the run with highest val_acc (run 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "af901b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration        0.151336\n",
       "round_epochs    0.209034\n",
       "lr                   NaN\n",
       "first_neuron    0.431531\n",
       "batch_size     -0.242086\n",
       "epochs          0.209034\n",
       "dropout        -0.098366\n",
       "Name: val_acc, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_object.correlate('val_acc', ['acc', 'loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f394e52",
   "metadata": {},
   "source": [
    "### Increasing the number of hidden layers for LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac10056",
   "metadata": {},
   "source": [
    "#### LSTM2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "169937aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 23s 10ms/step - loss: 1.2391 - accuracy: 0.4354\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 5s 10ms/step - loss: 1.1907 - accuracy: 0.4620\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 6s 12ms/step - loss: 1.1782 - accuracy: 0.4694\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 7s 12ms/step - loss: 1.1713 - accuracy: 0.4712\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 6s 11ms/step - loss: 1.1680 - accuracy: 0.4782\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 7s 12ms/step - loss: 1.1675 - accuracy: 0.4753\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 6s 10ms/step - loss: 1.1632 - accuracy: 0.4766\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 6s 11ms/step - loss: 1.1597 - accuracy: 0.4800\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 7s 12ms/step - loss: 1.1599 - accuracy: 0.4753\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 7s 13ms/step - loss: 1.1573 - accuracy: 0.4807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a942088400>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm2 = Sequential()                            \n",
    "model_lstm2.add(LSTM(16,\n",
    "                    activation='linear'))\n",
    "    \n",
    "model_lstm2.add(Dense(16,\n",
    "                    input_dim=X_train_lstm.shape[1],\n",
    "                    activation='relu'))\n",
    "model_lstm2.add(Dense(16,\n",
    "                    activation='relu'))\n",
    "    \n",
    "model_lstm2.add(Dense(4,\n",
    "                    activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001, decay = 1e-5)  # the optimizer settings can have a large impact. Decay, decreases the learning rate\n",
    "model_lstm2.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model_lstm2.fit(X_train_lstm, y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80d74951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 3s 9ms/step - loss: 1.1770 - accuracy: 0.4553\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model_lstm2.evaluate(X_test_lstm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df381b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 2s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.19      0.27       572\n",
      "           1       0.32      0.28      0.30      1007\n",
      "           2       0.28      0.16      0.20      1029\n",
      "           3       0.53      0.82      0.65      1756\n",
      "\n",
      "    accuracy                           0.46      4364\n",
      "   macro avg       0.40      0.36      0.35      4364\n",
      "weighted avg       0.42      0.46      0.41      4364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lstm2.predict(X_test_lstm)\n",
    "y_pred_sev = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74f0f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred_sev)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['0', '1','2', '3']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('LSTM2 Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701066e",
   "metadata": {},
   "source": [
    "### LSTM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f19fbb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "546/546 [==============================] - 5s 3ms/step - loss: 1.2169 - accuracy: 0.4454\n",
      "Epoch 2/20\n",
      "546/546 [==============================] - 2s 4ms/step - loss: 1.1809 - accuracy: 0.4655\n",
      "Epoch 3/20\n",
      "546/546 [==============================] - 2s 4ms/step - loss: 1.1765 - accuracy: 0.4689\n",
      "Epoch 4/20\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 1.1710 - accuracy: 0.4700\n",
      "Epoch 5/20\n",
      "546/546 [==============================] - 2s 4ms/step - loss: 1.1664 - accuracy: 0.4741\n",
      "Epoch 6/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1636 - accuracy: 0.4762\n",
      "Epoch 7/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1609 - accuracy: 0.4747\n",
      "Epoch 8/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1587 - accuracy: 0.4781\n",
      "Epoch 9/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1562 - accuracy: 0.4795\n",
      "Epoch 10/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1546 - accuracy: 0.4809\n",
      "Epoch 11/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1507 - accuracy: 0.4813\n",
      "Epoch 12/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1504 - accuracy: 0.4850\n",
      "Epoch 13/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1470 - accuracy: 0.4826\n",
      "Epoch 14/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1440 - accuracy: 0.4865\n",
      "Epoch 15/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1419 - accuracy: 0.4869\n",
      "Epoch 16/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1419 - accuracy: 0.4875\n",
      "Epoch 17/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1386 - accuracy: 0.4856\n",
      "Epoch 18/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1358 - accuracy: 0.4954\n",
      "Epoch 19/20\n",
      "546/546 [==============================] - 1s 3ms/step - loss: 1.1343 - accuracy: 0.4900\n",
      "Epoch 20/20\n",
      "546/546 [==============================] - 2s 3ms/step - loss: 1.1322 - accuracy: 0.4913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a96bc7d9a0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm2 = Sequential()                            \n",
    "model_lstm2.add(LSTM(16,\n",
    "                    activation='tanh'))\n",
    "    \n",
    "model_lstm2.add(Dense(16,\n",
    "                    input_dim=X_train_lstm.shape[1],\n",
    "                    activation='relu'))\n",
    "model_lstm2.add(Dense(16,\n",
    "                    activation='relu'))\n",
    "    \n",
    "model_lstm2.add(Dense(4,\n",
    "                    activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adamax(learning_rate = 0.01, decay = 1e-5)  # the optimizer settings can have a large impact. Decay, decreases the learning rate\n",
    "model_lstm2.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model_lstm2.fit(X_train_lstm, y_train, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "effff926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 1s 2ms/step - loss: 1.1914 - accuracy: 0.4581\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model_lstm2.evaluate(X_test_lstm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e1799305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.15      0.23       572\n",
      "           1       0.34      0.35      0.34      1007\n",
      "           2       0.30      0.17      0.22      1029\n",
      "           3       0.54      0.79      0.64      1756\n",
      "\n",
      "    accuracy                           0.46      4364\n",
      "   macro avg       0.42      0.36      0.36      4364\n",
      "weighted avg       0.43      0.46      0.42      4364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lstm2.predict(X_test_lstm)\n",
    "y_pred_sev = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2b2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
